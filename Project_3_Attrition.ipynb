{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMemdDDj_vf0"
      },
      "source": [
        "# Project 3 - Risk Factors for Attrition in Longitudinal Studies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By3IdmbKNLOS"
      },
      "source": [
        "## Mounts runtime to google drive, allowing access to cloud files\n",
        "## Also loads rpy2 kernel, allowing for R code chunks\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%reload_ext rpy2.ipython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAVkuXHJ8sZc"
      },
      "source": [
        "!pip install lifelines -q\n",
        "!pip install tableone -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9ZhupVA_53s"
      },
      "source": [
        "# Set-Up\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "from lifelines import KaplanMeierFitter\n",
        "import os\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_columns = 50\n",
        "\n",
        "datafolder = '/content/gdrive/My Drive/Attrition'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTroc7XBVm5p"
      },
      "source": [
        "%%R\n",
        "##Loads libraries required for analysis\n",
        "pack <- \"/content/gdrive/My Drive/R/packages\"\n",
        "\n",
        "library(data.table, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(dplyr, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"ggplot2\", lib.loc = pack)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"survival\", lib.loc = pack)\n",
        "library(\"survminer\", lib.loc = pack)\n",
        "library(tidyr, lib.loc = pack)\n",
        "library(knitr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PrepKM(data, cohort_dict):\n",
        "  new_data = pd.DataFrame()\n",
        "\n",
        "  flag = 0\n",
        "  data.loc[:,\"ID\"] = data.iloc[:,0]\n",
        "  data = data.loc[:,data.columns.isin([\"ID\"] + list(cohort_dict.values()))]\n",
        "  data = data.groupby(\"ID\").fillna(method=\"bfill\")\n",
        "  for key, val in cohort_dict.items():\n",
        "    if \"IS_\" in key:\n",
        "      new_data.loc[:,key] = [np.nan if pd.isnull(i) else 1 if i >= int(val.split(\"/\")[1]) else 0 for i in data[val.split(\"/\")[0]]]\n",
        "    elif val not in data.columns:\n",
        "      print(f\"Error: {val} not found\")\n",
        "    else:\n",
        "      new_data.loc[:,key] = data[val]\n",
        "      if flag == 1:\n",
        "        new_data.loc[~new_data.ID.duplicated(keep=\"first\"),f\"BL_{key}\"] = new_data.loc[:,key]\n",
        "        new_data.loc[:,f\"BL_{key}\"] = new_data.loc[:,f\"BL_{key}\"].fillna(method = \"ffill\")\n",
        "      if key == \"BL_AGE\":\n",
        "        flag = 1\n",
        "\n",
        "  if \"daysB\" not in new_data.columns:\n",
        "   new_data.insert(loc = 1, column = \"daysB\", value = new_data.DATE - new_data.BL_DATE)\n",
        "  new_data.loc[:,\"BL_durdx\"] = (new_data.BL_AGE - new_data.DX_AGE).round(2)\n",
        "  new_data.loc[:,\"durdx\"] = (new_data.BL_durdx + (new_data.daysB / 365.25)).round(2)\n",
        "  new_data.loc[:,\"COG\"] = new_data.groupby(\"ID\").COG.fillna(method = \"ffill\")\n",
        "\n",
        "  TD_data = new_data.copy()\n",
        "  TD_data.loc[:,\"LTF_TD\"] = 0 #[0 if k == 0 else 1 if i > j else 0 for i, j, k in zip(TD_data.DATE, TD_data.CENS_DT, TD_data.LTF)]\n",
        "  TD_data.loc[(~TD_data.duplicated(subset = \"ID\",keep=\"last\")) & (TD_data.LTF == 1), \"LTF_TD\"] = 1\n",
        "\n",
        "  TD_data.loc[:,\"TSTART\"] = TD_data.groupby(\"ID\").shift(1).loc[:,\"daysB\"]\n",
        "  TD_data = TD_data[TD_data.TSTART.notna()]\n",
        "  new_data = new_data.drop_duplicates(subset=\"ID\",keep=\"first\")\n",
        "  return(new_data, TD_data)"
      ],
      "metadata": {
        "id": "5cNMiQft2bhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FoxInsight"
      ],
      "metadata": {
        "id": "m0ikPkDmzGaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Enroll Date Estimation"
      ],
      "metadata": {
        "id": "uVcG0YU2jcln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now that we have proof of concept, I will attempt to recreate the dataset using raw data from FOX\n",
        "#First we need to establish a timeline (these files are large, so comment out to save time)\n",
        "RPD = pd.read_csv(f\"{datafolder}/FOX/ReturnPD.csv\")\n",
        "\n",
        "#Processing User data\n",
        "U = pd.read_csv(f\"{datafolder}/FOX/Users.csv\")\n",
        "U = U.loc[U.InitPDDiag == 1].drop(\"InitPDDiag\",axis=1) #Keep only participants with PD at baseline\n",
        "\n",
        "#Age and days_elapsed\n",
        "RPD = RPD.loc[RPD.fox_insight_id.isin(U.fox_insight_id)] #Keep only participants with PD at baseline based on U\n",
        "\n",
        "#To calculate baseline age (which will be used to identify days since baseline) we pull from Return PD\n",
        "BLA = RPD.loc[:,[\"fox_insight_id\",\"age\",\"days_elapsed\",\"schedule_of_activities\"]]\n",
        "BLA = BLA.loc[BLA.schedule_of_activities != \"REG\",:]\n",
        "BLA.loc[:,\"schedule_of_activities\"] = BLA.schedule_of_activities.astype(float) #Convert SOA to float, this will be used to estimate age at baseline\n",
        "\n",
        "BLA.loc[:,\"BL_AGE\"] = (BLA.age - (BLA.schedule_of_activities / 12)).round(2) #Calculate BL_AGE for each visit\n",
        "n_na_BLA = BLA[BLA.BL_AGE.isna()].fox_insight_id.nunique()\n",
        "BLA = BLA.dropna(subset = [\"BL_AGE\"]) #Remove NA values\n",
        "print(f\"{n_na_BLA} participants removed due to NA age at baseline\")\n",
        "\n",
        "#calculate baseline age and date, as well as registration age and date (sometimes the same, sometimes different)\n",
        "BLA = BLA.pivot_table(index=\"fox_insight_id\", values = [\"days_elapsed\",\"schedule_of_activities\",\"BL_AGE\"],\n",
        "                      aggfunc = {\"days_elapsed\":\"min\",\"schedule_of_activities\":\"min\",\"BL_AGE\":\"mean\"})\n",
        "BLA.loc[:,\"BL_DT\"] = BLA.days_elapsed - (BLA.schedule_of_activities * 30)\n",
        "BLA = BLA.loc[:,[\"BL_AGE\",\"BL_DT\"]]\n",
        "BLA = BLA.join(U.set_index(\"fox_insight_id\").loc[:,[\"AgeAtEnrollment\",\"days_elapsed\"]]).rename({\"AgeAtEnrollment\":\"REG_AGE\",\"days_elapsed\":\"REG_DT\"},axis=1)\n",
        "\n",
        "#Save key for later use\n",
        "k = BLA.loc[:,[\"BL_AGE\",\"BL_DT\"]].copy()\n",
        "\n",
        "#Rewrite ReturnPD df including new variables\n",
        "RPD = BLA.join(RPD.loc[:,[\"fox_insight_id\",\"days_elapsed\"]].set_index(\"fox_insight_id\"))\n",
        "RPD.loc[:,\"daysB\"] = RPD.days_elapsed - RPD.BL_DT #calculate time since baseline\n",
        "\n",
        "#Some participants with changing diagnosis have negative daysB, so we remove these participants\n",
        "ng_db = RPD[RPD.daysB < -90].index #We allow for a period of -90 to account for any time window abnormalities\n",
        "RPD = RPD[~RPD.index.isin(ng_db)]#Remove NA values\n",
        "print(f\"{ng_db.nunique()} participants removed due to negative days since baseline\")\n",
        "\n",
        "'''\n",
        "Return PD and Users data were obtained on 4/18/2022. Up until September 2019, participants were able\n",
        "to complete their visits within a 90 day window (post this the window was 30 days). However, despite\n",
        "this the majority of participants completed their surveys within 30 days (see ReturnPD days_acquired).\n",
        "Based on this information, the earliest possible date of any last visit in this dataset would be\n",
        "1/18/22 and we can estimate the earliest enrollment date.\n",
        "'''\n",
        "#In this case max db refers to the maximum days since baseline, in other words the latest possible visit for a participant\n",
        "max_db = RPD.pivot_table(index = \"fox_insight_id\", values = \"daysB\", aggfunc = \"max\")\n",
        "\n",
        "#We assume a normal distribution of visit dates, so we can estimate start date within a 95%\n",
        "max_db.loc[:,\"START_DT\"] = [pd.to_datetime(\"3/1/22\") - dt.timedelta(days = d) for d in max_db.daysB]\n",
        "\n",
        "RPD = RPD.join(max_db.loc[:,\"START_DT\"])\n",
        "\n",
        "RPD.describe()"
      ],
      "metadata": {
        "id": "esR9xBMdmiBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogram of Estimated Enrollment Dates\n",
        "print(f\"{max_db.index.nunique()} participants total\")\n",
        "hist = px.histogram(max_db, x = \"START_DT\", height = 750, width = 1000, nbins = 20,\n",
        "                    title = \"Histogram of Estimate Start Date\", labels = {'START_DT':\"Estimated Date of Baseline\",'y':\"Number of Participants\"}, text_auto=True)\n",
        "hist.layout.yaxis.title.text = \"Number of Participants\"\n",
        "# hist.data[0].texttemplate = \"%{x}\"\n",
        "hist"
      ],
      "metadata": {
        "id": "ghIY87CtEzFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZt8i7kddXeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What year-long enrollment period collects the most participants?\n",
        "max = 0\n",
        "for year in [2016,2017,2018,2019,2020,2021,2022]:\n",
        "  for month in range(1,13,3):\n",
        "    n = ((dt.datetime(year=year,month=month,day=1) < max_db.loc[:,\"START_DT\"]) & (max_db.loc[:,\"START_DT\"] < dt.datetime(year=year+1, month=month,day = 1))).sum()\n",
        "    if n > max:\n",
        "      print(f\"The new max enroll start date is {month}/{year} with {n} participants\")\n",
        "      max = n"
      ],
      "metadata": {
        "id": "i6wP5Er_iDpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Determine Inactivity\n",
        "To determine inactivity, we pull data from all surveys administered to PD participants at a frequency of every six months or more often."
      ],
      "metadata": {
        "id": "-qTbQ5dimByl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load longitudinal data last collected on 4/20\n",
        "# L = pd.read_csv(f\"{datafolder}/FOX/LONG-420.csv\")\n",
        "# L = L[L.fox_insight_id.isin(k.index)]\n",
        "# k1 = k.join(L.set_index(\"fox_insight_id\"))\n",
        "\n",
        "'''\n",
        "To determine inactivity, we cycle through all of the surveys administered on a regular basis by Fox\n",
        "Insight and identify the latest value of days_elapsed for each participant. Comparing this value to\n",
        "the value of maximum possible daysB established by the ReturnPD survey allows us to establish a\n",
        "period of activity and inactivity.\n",
        "'''\n",
        "\n",
        "k1 = pd.DataFrame()\n",
        "for csv in os.listdir(f\"{datafolder}/FOX/\"):\n",
        "  if \"csv\" in csv:\n",
        "    df = pd.read_csv(f\"{datafolder}/FOX/{csv}\")\n",
        "    if (\"days_elapsed\" in df.columns) & ~(csv in [\"ReturnPD.csv\",\"Users.csv\",\"About.csv\"]): #These three have different definitions for days_elapsed\n",
        "      df = df.loc[:,[\"fox_insight_id\",\"days_elapsed\"]]\n",
        "      k1 = k1.append(df).drop_duplicates().sort_values([\"fox_insight_id\",\"days_elapsed\"])\n",
        "# pd.read_csv(f\"{datafolder}/FOX/Medications.csv\")\n",
        "\n",
        "k1 = k.join(k1.set_index(\"fox_insight_id\"))\n",
        "\n",
        "#Round negative values of daysB to 0, we already cleaned far outliers in previous chunk, so this just finishes the job\n",
        "k1.loc[:,\"daysB\"] = [0 if d < 0 else d for d in (k1.days_elapsed - k1.BL_DT)]\n",
        "k1.loc[:,\"VM\"] = (k1.daysB / 90).round(0) * 3\n",
        "\n",
        "\n",
        "k1 = (k1.join(k1.reset_index()\n",
        "              .drop_duplicates(subset = [\"fox_insight_id\",\"VM\"],keep=\"first\")\n",
        "              .pivot_table(index=[\"fox_insight_id\"],values=[\"VM\"],aggfunc =\"count\")\n",
        "              .rename({\"VM\":\"NVISITS\"},axis=1)))\n",
        "\n",
        "k1 = k1.join((k1.reset_index().loc[(k1.VM <= 24).values]\n",
        "                 .drop_duplicates(subset = [\"fox_insight_id\",\"VM\"],keep=\"first\")\n",
        "                 .pivot_table(index=[\"fox_insight_id\"],values=[\"VM\"],aggfunc =\"count\")\n",
        "                 .rename({\"VM\":\"NVISITS24\"},axis=1)))\n",
        "\n",
        "k1 = k1[~k1.index.duplicated(keep = \"last\")]\n",
        "\n",
        "k1.loc[:,\"ACT\"] = k1.days_elapsed - k1.BL_DT\n",
        "\n",
        "k1 = max_db.rename({\"daysB\":\"max_daysB\"},axis=1).join(k1)\n",
        "\n",
        "k1.loc[:,\"INACT\"] = k1.max_daysB - k1.ACT\n",
        "\n",
        "k1.loc[:,\"DROP_DT\"] = [st + dt.timedelta(days = dat) if ina > 90 else np.nan for st,dat,ina in zip(k1.START_DT,k1.ACT,k1.INACT)]\n",
        "\n",
        "k1"
      ],
      "metadata": {
        "id": "l_IAoaC1rfBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "px.histogram(k1.DROP_DT,nbins = 20)"
      ],
      "metadata": {
        "id": "Qxvej9GQ2ETS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k1.INACT.describe()"
      ],
      "metadata": {
        "id": "HoECuAfietga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for thresh in range(3,24,3):\n",
        "  print(f\"{((k1.ACT / 30 > thresh).sum() / len(k1.ACT) * 100).round(2)} percent attrition with threshold of {thresh}\")\n",
        "px.histogram(k1.ACT, nbins = int(k1.ACT.max() / 90))"
      ],
      "metadata": {
        "id": "GEqUo7RzeYNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Produce covariates"
      ],
      "metadata": {
        "id": "c54tVpMwRX57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This section involves remapping covariates for analysis. Here we use the raw var to load onto the\n",
        "cov dataframe. cov dataframe relies on key created in previous code chunks\n",
        "'''\n",
        "cov = k.copy()\n",
        "cov.loc[:,\"BL_AGE\"] = cov.BL_AGE.round(1)\n",
        "\n",
        "#From about file, we can pull race, ethnicity, income, employment, veteran status, and previous research involvement\n",
        "raw = (pd.read_csv(f\"{datafolder}/FOX/About.csv\")\n",
        "        .drop([\"age\",\"days_elapsed\",\"days_acquired\",\"schedule_of_activities\",\"HeightPNA\",\n",
        "               \"HeightInch\",\"HeightCm\",\"WeightPNA\",\"WeightKgs\",\"WeightLbs\"], axis=1)\n",
        "        .drop_duplicates(subset = \"fox_insight_id\", keep=\"first\"))\n",
        "raw = raw.loc[raw.fox_insight_id.isin(k.index),:]\n",
        "\n",
        "#Process Sex\n",
        "raw.loc[:,\"SEX\"] = raw.Sex.map({1:\"Male\",2:\"Female\"})\n",
        "raw = raw.drop(\"Sex\",axis=1)\n",
        "\n",
        "#Process Ethnicity\n",
        "raw.loc[:,\"ETHN\"] = [ \"HISP\" if (nh==1) and (m==p==c==l==0)\n",
        "                      else \"NONH\" if (nh==0) and (m+p+c+l)>0\n",
        "                      else np.nan for (nh,m,p,c,l) in zip( raw['EthnNotHispanic'], raw['EthnMexican'], raw['EthnPuerto'], raw['EthnCuban'], raw['EthnLatino'])]\n",
        "raw = raw.drop(raw.columns[raw.columns.str.contains(\"Ethn\")],axis=1)\n",
        "\n",
        "#Process Race\n",
        "raw.loc[:,\"RACE\"] = ['HISP' if (w == 1) and (hs == \"HISP\")\n",
        "                    else 'WHIT' if (w==1) and (aa==ai==a==nh==0)\n",
        "                    else 'BLCK' if (aa==1) and (w==ai==a==nh==0)\n",
        "                    else 'ASIA' if (a==1) and (w==ai==aa==nh==0)\n",
        "                    else 'OTH' if (w+aa+ai+a+nh)>0\n",
        "                    else np.nan for (w,aa,ai,a,nh,hs) in zip(\n",
        "                    raw['RaceW'], raw['RaceAA'], raw['RaceAI'], raw['RaceA'], raw['RaceNH'], raw[\"ETHN\"])]\n",
        "raw = raw.drop([\"RaceAA\",\"RaceAI\",\"RaceA\",\"RaceNH\",\"RacePNA\"],axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Process education as a categorical with four levels; <HS (Less than High School),HS (High School or Some College),\n",
        "# UNI (Bachelor's or Associate),UNI+ (Doctorate or Master's)\n",
        "raw.loc[:,\"EDUC\"] = [\"<HS\" if e == 1\n",
        "                           else \"HS\" if e in [2,3]\n",
        "                           else \"UNI\" if e in [4,5]\n",
        "                           else \"UNI+\" if e in [6,7,8]\n",
        "                           else np.nan for e in raw.Education]\n",
        "\n",
        "raw.loc[:,\"EDUCYRS\"] = raw.Education.map({1:8, 2:12, 3:12, 4:14, 5:16, 6:18, 7:20, 8:20})\n",
        "raw = raw.drop(\"Education\",axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Process income as a categorical with 3 levels; <50k, 50-100k, >100k\n",
        "raw.loc[:,\"INCM3\"] = [0 if i in [1,2,3]\n",
        "                       else 1 if i in [4,5]\n",
        "                       else 2 if i == 6\n",
        "                       else np.nan for i in raw.Income]\n",
        "raw = raw.rename({\"Income\":\"INCM7\"},axis=1) #We also preserve the initial income coding as income with 7 levels\n",
        "\n",
        "#Employment status as a categorical with fulltime, parttime, retired, and unemployed status\n",
        "raw.loc[:,\"EMPL\"] = [\"EMP\" if e in [1,2]\n",
        "                     else \"RET\" if e == 3\n",
        "                     else \"UNEMP\" if e == 4\n",
        "                     else np.nan for e in raw.Employment]\n",
        "raw = raw.drop(\"Employment\",axis=1)\n",
        "\n",
        "#Add combined employment/income outcome\n",
        "raw.loc[:,\"SES\"] = [\"RET\" if e == \"RET\"\n",
        "                        else \"UNEMP\" if e == \"UNEMP\"\n",
        "                        else \"EMP>50\" if i in [1,2]\n",
        "                        else \"EMP<50\" if i == 0\n",
        "                        else np.nan for i,e in zip(raw.INCM3,raw.EMPL)]\n",
        "\n",
        "#Veteran and Research status require minimal cleaning\n",
        "raw.loc[:,\"VET\"] = raw.Veteran.map({0:0,1:1,3:np.nan})\n",
        "raw.loc[:,\"RSRC\"] = raw.Research.map({0:0,1:1,3:np.nan})\n",
        "raw = raw.drop([\"Veteran\",\"Research\"],axis=1)\n",
        "\n",
        "#Join demographics to key\n",
        "cov = cov.join(raw.set_index(\"fox_insight_id\"))\n",
        "\n",
        "raw = pd.read_csv(f\"{datafolder}/FOX/Users.csv\").loc[:,[\"fox_insight_id\",\"LocCountry\",\"InitPDDiagAge\"]]\n",
        "\n",
        "raw = (raw.loc[raw.fox_insight_id.isin(k.index),:]\n",
        "          .rename({\"LocCountry\":\"LOC\",\"InitPDDiagAge\":\"BL_DDX\"},axis=1)\n",
        "          .set_index(\"fox_insight_id\"))\n",
        "\n",
        "cov = cov.join(raw)\n",
        "\n",
        "cov.loc[:,\"BL_DDX\"] = cov.BL_AGE - cov.BL_DDX\n",
        "\n",
        "#Measure of ADLs is captured in \"Your Movement Experiences\" Survey (UPDRS2)\n",
        "raw = pd.read_csv(f\"{datafolder}/FOX/Movement.csv\").drop_duplicates(subset=\"fox_insight_id\",keep=\"first\")\n",
        "UP2_ITEMS = raw.columns[raw.columns.str.contains(\"Move\")][1:]\n",
        "UP2_ITEMS = dict(zip(UP2_ITEMS, [i.replace(\"Move\",\"UP2_\").upper()for i in UP2_ITEMS]))\n",
        "raw.loc[:,\"BL_UP2\"] = raw.loc[:,UP2_ITEMS.keys()].sum(axis=1, skipna=False)\n",
        "raw.loc[:,\"PROXY\"] = raw.MoveWho.replace({1:0,2:1,3:1})#.replace({1:\"PT\",2:\"CG\",3:\"PT/CG\"})\n",
        "raw = raw.rename(UP2_ITEMS, axis=1)\n",
        "raw = raw.loc[:,list(UP2_ITEMS.values()) + [\"fox_insight_id\",\"BL_UP2\",\"PROXY\"]].set_index(\"fox_insight_id\")\n",
        "\n",
        "cov = cov.join(raw)\n",
        "\n",
        "# #Measure of Motor Function is captured in \"Brief Motor Screen\" Survey\n",
        "# raw = pd.read_csv(f\"{datafolder}/FOX/Brief_Motor_Screen.csv\")\n",
        "# raw.loc[:,\"FID\"] = raw.fox_insight_id\n",
        "# raw = raw.loc[:,raw.columns[raw.columns.str.contains(\"id|MtrScrn\",case=False)]]\n",
        "# raw = raw.groupby(\"FID\").fillna(method=\"backfill\")\n",
        "# raw = raw.drop_duplicates(subset=\"fox_insight_id\",keep=\"first\")\n",
        "# raw.loc[:,\"BL_BMS\"] = raw.loc[:,raw.columns[raw.columns.str.contains(\"MtrScrn\")]].replace({2:np.nan}).sum(axis=1, skipna=True)\n",
        "# raw = raw.loc[:,[\"fox_insight_id\",\"BL_BMS\"]].set_index(\"fox_insight_id\")\n",
        "# raw\n",
        "\n",
        "# cov = cov.join(raw)\n",
        "\n",
        "# Living status is reported in the \"Return PD\" survey\n",
        "# This presented a problem because it conflicted with attrition definition significnatly\n",
        "RPD = pd.read_csv(f\"{datafolder}/FOX/ReturnPD.csv\").set_index(\"fox_insight_id\")\n",
        "\n",
        "RPD.loc[:,\"LIVSUM\"] = RPD.loc[:,RPD.columns.str.contains(\"Live\")].sum(axis=1).replace({0:np.nan})\n",
        "RPD = RPD.dropna(subset = [\"LIVSUM\"])\n",
        "RPD = RPD.loc[~RPD.index.duplicated(keep=\"first\")].drop(\"LIVSUM\",axis=1)\n",
        "\n",
        "RPD.loc[:,\"LIV\"] = [\"wspouse\" if sp == 1\n",
        "                    else \"wfam\"  if (ach + mch + of) > 0\n",
        "                    else \"wcare\" if ct == 1\n",
        "                    else \"@ass\" if (ass + nh) > 0\n",
        "                    else \"alone\" if a == 1\n",
        "                    else np.nan for a,sp,ach,mch,of,ct,ass,nh in zip(RPD.LiveAlonePD,RPD.LiveSpousePD,\n",
        "                                                             RPD.LiveAdultPD, RPD.LiveMinorPD,\n",
        "                                                             RPD.LiveOthFamPD, RPD.LiveCarePD,\n",
        "                                                             RPD.LiveAsstPD, RPD.LiveNursPD)]\n",
        "RPD.loc[:,\"LIVASS\"] = [1 if (al + nh) > 0 else 0 for al, nh in zip(RPD.LiveAsstPD, RPD.LiveNursPD)]\n",
        "RPD.loc[:,\"LIVFAM\"] = [1 if (ach + mch + of + sp) > 0 else 0 for sp,ach,mch,of in zip(RPD.LiveSpousePD,\n",
        "                                                             RPD.LiveAdultPD, RPD.LiveMinorPD,\n",
        "                                                             RPD.LiveOthFamPD, )]\n",
        "\n",
        "\n",
        "\n",
        "RPD = RPD.loc[:,[\"LIV\",\"LIVASS\",\"LIVFAM\",\"LiveAlonePD\",\"LiveCarePD\"]]\n",
        "\n",
        "cov = cov.join(RPD)\n",
        "\n",
        "#Measure of Cognitive Impairment is captured in \"Your Cognition and Daily Activities\" Survey (PDAQ)\n",
        "raw = pd.read_csv(f\"{datafolder}/FOX/DailyActivity.csv\").drop_duplicates(subset=\"fox_insight_id\",keep=\"first\")\n",
        "raw.loc[:,\"BL_PDAQ\"] = raw.loc[:,raw.columns[raw.columns.str.contains(\"Daily\")]].sum(axis=1, skipna=False)\n",
        "raw.loc[:,\"BL_MCI\"] = [1 if p <= 43 else 0 for p in raw.BL_PDAQ]\n",
        "raw.loc[:,\"BL_DEM\"] = [1 if p <= 37 else 0 for p in raw.BL_PDAQ]\n",
        "raw.loc[:,\"BL_COG\"] = [2 if p <= 37 else 1 if p <= 47 else 0 for p in raw.BL_PDAQ]\n",
        "raw = raw.loc[:,[\"fox_insight_id\",\"BL_PDAQ\",\"BL_MCI\",\"BL_DEM\",\"BL_COG\"]].set_index(\"fox_insight_id\")\n",
        "\n",
        "cov = cov.join(raw)\n",
        "\n",
        "#Measure of Depressive Symptoms is captured in \"Your Mood\" Survey (GDS-15)\n",
        "raw = pd.read_csv(f\"{datafolder}/FOX/Mood.csv\").drop_duplicates(subset=\"fox_insight_id\",keep=\"first\")\n",
        "raw.loc[:,[\"MoodSatis\",\"MoodSpirits\",\"MoodHappy\",\"MoodAlive\",\"MoodEnergy\"]] = raw.loc[:,[\"MoodSatis\",\"MoodSpirits\",\"MoodHappy\",\"MoodAlive\",\"MoodEnergy\"]].replace({0:1,1:0})\n",
        "raw.loc[:,\"BL_DEP\"] = raw.loc[:,raw.columns[raw.columns.str.contains(\"Mood\")]].sum(axis=1,skipna=True)\n",
        "raw.loc[:,\"IS_DEP\"] = [1 if d > 5 else 0 if d < 5 else 0 for d in raw.BL_DEP]\n",
        "raw = raw.loc[:,[\"fox_insight_id\",\"BL_DEP\",\"IS_DEP\"]].set_index(\"fox_insight_id\")\n",
        "\n",
        "cov = cov.join(raw)\n",
        "\n",
        "#Measure of physical activity is captured in \"Your Physical Activities\"\n",
        "raw = pd.read_csv(f\"{datafolder}/FOX/PASE.csv\").drop_duplicates(subset=\"fox_insight_id\",keep=\"first\")\n",
        "\n",
        "PASE_dict = dict(zip(raw.columns[7:],[\"Q2\",\"Q2a\",\"Q3\",\"Q3a\",\"Q4\",\"Q4a\",\"Q5\",\"Q5a\",\"Q6\",\"Q6a\",\n",
        "                          \"Q7\",\"Q8\",\"Q9a\",\"Q9b\",\"Q9c\",\"Q9d\",\"Q10\",\"Q10a\"]))\n",
        "raw = raw.rename(PASE_dict,axis=1).replace({np.nan:0})\n",
        "wts = dict(zip([\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q7\",\"Q8\",\"Q9a\",\"Q9b\",\"Q9c\",\"Q9d\",\"Q10\"],\n",
        "                   [20,21,23,23,30,25,25,30,36,20,35,21]))\n",
        "\n",
        "HPDqs = [\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\"]\n",
        "for q in HPDqs:\n",
        "  raw.loc[:,f\"{q}t\"] = [wts[q] * .11 if  (qd == 1) & (qh == 1)\n",
        "                        else wts[q] * .32 if  (qd == 1) & (qh == 2)\n",
        "                        else wts[q] * .64 if  (qd == 1) & (qh == 3)\n",
        "                        else wts[q] * 1.07 if (qd == 1) & (qh == 4)\n",
        "                        else wts[q] * .25 if  (qd == 2) & (qh == 1)\n",
        "                        else wts[q] * .75 if  (qd == 2) & (qh == 2)\n",
        "                        else wts[q] * 1.50 if  (qd == 2) & (qh == 3)\n",
        "                        else wts[q] * 2.50 if (qd == 2) & (qh == 4)\n",
        "                        else wts[q] * .43 if  (qd == 3) & (qh == 1)\n",
        "                        else wts[q] * 1.29 if  (qd == 3) & (qh == 2)\n",
        "                        else wts[q] * 2.57 if  (qd == 3) & (qh == 3)\n",
        "                        else wts[q] * 4.29 if (qd == 3) & (qh == 4)\n",
        "                        else 0 for qd, qh in zip(raw.loc[:,q],raw.loc[:,f\"{q}a\"])]\n",
        "raw = raw.drop(HPDqs + [f\"{q}a\" for q in HPDqs], axis=1)\n",
        "\n",
        "qset2 = [\"Q7\",\"Q8\",\"Q9a\",\"Q9b\",\"Q9c\",\"Q9d\"]\n",
        "for q in qset2:\n",
        "  raw.loc[:,f\"{q}t\"] = [n * wts[q] for n in raw.loc[:,q]]\n",
        "raw.drop(qset2,axis=1)\n",
        "\n",
        "raw.loc[:,\"Q10t\"] = [21 if (ten == 1) * (tena > 1) else 0 for ten, tena in zip(raw.Q10,raw.Q10a)]\n",
        "\n",
        "raw.loc[:,\"LEIS\"] = raw.LeisureDay * raw.LeisureHours\n",
        "\n",
        "raw.loc[:,\"PASE\"] = raw.loc[:,raw.columns[raw.columns.str.contains(\"t$\")]].sum(axis=1)\n",
        "\n",
        "raw = raw.set_index(\"fox_insight_id\").loc[:,[\"LEIS\",\"PASE\"]]\n",
        "\n",
        "cov = cov.join(raw)\n",
        "\n",
        "cov"
      ],
      "metadata": {
        "id": "Cyyr9l7IRaF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HyyOAAOL2VO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Produce final dataset"
      ],
      "metadata": {
        "id": "is8eYof0dl87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Timeline Objects"
      ],
      "metadata": {
        "id": "278CBIQocYVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enroll_dts =  k1.loc[:,\"START_DT\"]\n",
        "\n",
        "\n",
        "tl1 = ((dt.datetime(year=2017,month=10,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2018, month=10,day = 1)))\n",
        "print(f'{tl1.sum()} participants in max enroll timeline')\n",
        "tl2 = ((dt.datetime(year=2017,month=3,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2018, month=3,day = 1)))\n",
        "print(f'{tl2.sum()} participants in pre-COVID timeline')\n",
        "tl3 = ((dt.datetime(year=2019,month=3,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2020, month=3,day = 1)))\n",
        "print(f'{tl3.sum()} participants in COVID follow-up timeline')\n",
        "tl4 = ((dt.datetime(year=2020,month=3,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2021, month=3,day = 1)))\n",
        "print(f'{tl4.sum()} participants in COVID recruitment timeline')\n",
        "tl5 = ((dt.datetime(year=2019,month=9,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2020, month=9,day = 1)))\n",
        "print(f'{tl5.sum()} participants in post time window change timeline')\n",
        "tl6 = ((dt.datetime(year=2018,month=10,day=2) < enroll_dts) & (enroll_dts < dt.datetime(year=2019, month=10,day = 1)))\n",
        "print(f'{tl6.sum()} participants in year 2 recruitment timeline')\n",
        "\n",
        "#Now we can produce our complete dataset and filter based on dates of activity\n",
        "#Set parameters\n",
        "tlps = [tl1[tl1].index, tl2[tl2].index, tl3[tl3].index, tl4[tl4].index, tl5[tl5].index,tl6[tl6].index]\n",
        "tlns = [f\"TL{i}\" for i in range(1,7)]\n",
        "FUPs = [24,48,12,12,15,24]\n",
        "\n",
        "#Create dataframes\n",
        "for tlp, tln, FUP in zip(tlps, tlns, FUPs):\n",
        "  print(f\"************Running {tln} with follow-up of {FUP} months************\")\n",
        "  cdat = k1.drop([\"BL_AGE\",\"BL_DT\"],axis=1).join(cov)\n",
        "  cdat = cdat[cdat.index.isin(tlp)]\n",
        "  cdat.insert(2, \"LTF\", [0 if act > (FUP * 30) else 1 for act in cdat.ACT])\n",
        "  cdat.loc[:,\"daysB\"] = [(FUP * 30) if act >= (FUP * 28) else act for act in cdat.ACT]\n",
        "\n",
        "  covars = [\"daysB\",\"BL_AGE\",\"BL_DDX\",\"SEX\",\"RSRC\",\"RACE\", \"ETHN\", \"EDUC\", \"INCM7\", \"INCM3\", \"EMPL\", \"VET\",\n",
        "        \"BL_UP2\",\"BL_COG\",\"BL_DEP\",\"PROXY\",\"PASE\"]\n",
        "\n",
        "  print(f\"{cdat.index.nunique()} participants before cleaning\")\n",
        "  for col in covars:\n",
        "    print(f\"dropping {cdat[cdat.loc[:,col].isna()].index.nunique()} participants due to {col}\")\n",
        "    cdat = cdat.dropna(subset = [col])\n",
        "  npart = cdat.index.nunique()\n",
        "  print(f\"{npart} participants after cleaning\")\n",
        "\n",
        "  cdat.loc[:,\"UNOS\"] = [1 if nv == 1 else 0 for nv in cdat.NVISITS24]\n",
        "\n",
        "  print(f\"{cdat[cdat.UNOS == 1].index.nunique()} participants with only one visit ({round(cdat[cdat.UNOS == 1].index.nunique() * 100 / npart, 1)}%)\")\n",
        "\n",
        "  cdat.loc[:,\"NONCOMP\"] = [0 if ((nv / ((FUP / 3) + 1))) > 0.5 else 1 for nv in cdat.NVISITS24]\n",
        "\n",
        "  n_ncmp = cdat[cdat.NONCOMP == 1].index.nunique()\n",
        "  print(f\"{n_ncmp} compliant participants ({round(n_ncmp * 100 / npart, 1)}%)\")\n",
        "\n",
        "  cdat.to_csv(f\"FOX_{tln}_LTF{FUP}.csv\")\n",
        "  print(f'{cdat[cdat.LTF == 1].index.nunique()} participants lost to follow up ({round(cdat[cdat.LTF == 1].index.nunique() * 100 / npart, 1)}%)')"
      ],
      "metadata": {
        "id": "zjJX35w6leIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl1 = pd.read_csv(\"FOX_TL1_LTF24.csv\")\n",
        "print(\"***Compliance and Attrition Parameters for Returning Participants of TL1****\")\n",
        "print(tl1[tl1.UNOS == 0].NONCOMP.value_counts())\n",
        "print(tl1[tl1.UNOS == 0].LTF.value_counts())"
      ],
      "metadata": {
        "id": "duUL9skMPKub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tl1 = pd.read_csv(\"FOX_TL6_LTF24.csv\")\n",
        "print(\"***Noncompliance and Attrition Parameters for Returning Participants of TL6****\")\n",
        "print(tl1[tl1.UNOS == 0].NONCOMP.value_counts())\n",
        "print(tl1[tl1.UNOS == 0].LTF.value_counts())"
      ],
      "metadata": {
        "id": "xd9gli34QHfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov.reset_index().pivot_table(index = \"EMPL\",columns = \"INCM\",values = \"fox_insight_id\", aggfunc = \"count\")"
      ],
      "metadata": {
        "id": "xFmBPClyArO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Year Timeline\n"
      ],
      "metadata": {
        "id": "j71WPzjacILg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Return Participation"
      ],
      "metadata": {
        "id": "mEyvUnJRmi7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "LTFdf$RACE <- relevel(factor(LTFdf$RACE), ref = \"WHIT\")\n",
        "LTFdf$EDUC <- relevel(factor(LTFdf$EDUC), ref = \"HS\")\n",
        "# LTFdf$PROXY <- relevel(factor(LTFdf$PROXY), ref = \"PT\")\n",
        "\n",
        "print(\"******************COMPARING ONE-TIMERS AND RETURNERS*****************\")\n",
        "RTLM_Y1 <- glm(formula = UNOS  ~ (SEX + I(BL_AGE/5) + RACE + EDUC + factor(INCM3) + EMPL + RSRC + PASE + PROXY + I(BL_DDX/5) + BL_UP2 + factor(BL_COG) + IS_DEP),\n",
        "             data = LTFdf, family = \"binomial\")\n",
        "print(summary(RTLM_Y1))\n",
        "print(exp(coef(RTLM_Y1)))"
      ],
      "metadata": {
        "id": "9yuBobSw9fJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "\n",
        "probabilities <- predict(RTLM_Y1, type = \"response\")\n",
        "predicted.classes <- ifelse(probabilities > 0.5, \"pos\", \"neg\")\n",
        "\n",
        "mydata <- LTFdf %>%\n",
        "         select(c(\"BL_AGE\",\"BL_DDX\",\"BL_UP2\"))\n",
        "predictors <- colnames(mydata)\n",
        "mydata <- mydata %>%\n",
        "         mutate(logit = log(probabilities/(1-probabilities))) %>%\n",
        "         gather(key = \"predictors\", value = \"predictor.value\", -logit)\n",
        "\n",
        "\n",
        "ggplot(mydata, aes(logit, predictor.value))+\n",
        "  geom_point(size = 0.5, alpha = 0.5) +\n",
        "  geom_smooth(method = \"loess\") +\n",
        "  theme_bw() +\n",
        "  facet_wrap(~predictors, scales = \"free_y\")"
      ],
      "metadata": {
        "id": "9LMpUnxbhyWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nonadherence\n"
      ],
      "metadata": {
        "id": "zkRgA0eqhvfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "print(\"******************NONCOMPLIANCE ANALYSIS*****************\")\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "\n",
        "NCLM_Y1 <- glm(formula = NONCOMP ~ (SEX + I(BL_AGE/5) + RACE + EDUC + factor(INCM3) + EMPL + RSRC + PASE + PROXY + I(BL_DDX/5) + BL_UP2 + factor(BL_COG) + IS_DEP),\n",
        "             data = filter(LTFdf, UNOS == 0), family = \"binomial\")\n",
        "print(summary(NCLM_Y1))\n",
        "print(exp(coef(NCLM_Y1)))"
      ],
      "metadata": {
        "id": "-IXsKU0Amcr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "\n",
        "probabilities <- predict(NCLM_Y1, type = \"response\")\n",
        "predicted.classes <- ifelse(probabilities > 0.5, \"pos\", \"neg\")\n",
        "\n",
        "mydata <- LTFdf %>%\n",
        "         filter(UNOS == 0) %>%\n",
        "         select(c(\"BL_AGE\",\"BL_DDX\",\"BL_UP2\"))\n",
        "predictors <- colnames(mydata)\n",
        "mydata <- mydata %>%\n",
        "         mutate(logit = log(probabilities/(1-probabilities))) %>%\n",
        "         gather(key = \"predictors\", value = \"predictor.value\", -logit)\n",
        "\n",
        "\n",
        "ggplot(mydata, aes(logit, predictor.value))+\n",
        "  geom_point(size = 0.5, alpha = 0.5) +\n",
        "  geom_smooth(method = \"loess\") +\n",
        "  theme_bw() +\n",
        "  facet_wrap(~predictors, scales = \"free_y\")"
      ],
      "metadata": {
        "id": "ZZrjQ5BymgPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cox LTF"
      ],
      "metadata": {
        "id": "PfE2Pu5MnZNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "print(\"******************MAX ENROLLMENT*****************\")\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "LTFdf$RACE <- relevel(factor(LTFdf$RACE), ref = \"WHIT\")\n",
        "\n",
        "LTF_Y1 <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + I(BL_AGE/5) + RACE + EDUC + factor(INCM3) + EMPL + RSRC + PASE + PROXY + I(BL_DDX/5) + BL_UP2 + factor(BL_COG) + IS_DEP),\n",
        "             data = filter(LTFdf, UNOS == 0))\n",
        "res = cbind(exp(coef(LTF_Y1)), exp(confint(LTF_Y1)), coef(summary(LTF_Y1))[,5])\n",
        "colnames(res) <- c(\"OR\",\"CI2.5%\",\"CI97.5%\",\"P\")\n",
        "res <- signif(res, digits=3)\n",
        "\n",
        "\n",
        "g <- ggsurvplot(fit = survfit(Surv(daysB, LTF == 1) ~ 1, data = filter(LTFdf, UNOS == 0)),\n",
        "    xlab = \"Days Since Baseline\",\n",
        "    ylab = \"Probability of Patient Remaining in Study\",\n",
        "    title = \"Likelihood of Attrition in Fox Insight Year One\",\n",
        "    legend.title = \"\",\n",
        "    risk.table.y.text = F,\n",
        "    risk.table = TRUE)\n",
        "\n",
        "print(summary(LTF_Y1))\n",
        "print(res)\n",
        "print(g)"
      ],
      "metadata": {
        "id": "w_plUAxMhxur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### UP2"
      ],
      "metadata": {
        "id": "5PD8hro9ndBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "print(\"******************MAX ENROLLMENT*****************\")\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "LTFdf$RACE <- relevel(factor(LTFdf$RACE), ref = \"WHIT\")\n",
        "\n",
        "UP2_Y1 <- coxph(formula = Surv(daysB, LTF == 1) ~ UP2_SPEECH+UP2_SALIVA+UP2_CHEW+UP2_EAT+UP2_DRESS+UP2_HYGIENE+UP2_WRITE+UP2_HOBBY+UP2_SLEEP+UP2_TREMOR+UP2_UP+UP2_WALK+UP2_FREEZE,\n",
        "             data = filter(LTFdf, UNOS == 0))\n",
        "res = cbind(exp(coef(UP2_Y1)), exp(confint(UP2_Y1)), coef(summary(UP2_Y1))[,5])\n",
        "colnames(res) <- c(\"OR\",\"CI2.5%\",\"CI97.5%\",\"P\")\n",
        "res <- signif(res, digits=3)\n",
        "\n",
        "print(summary(UP2_Y1))\n",
        "print(res)"
      ],
      "metadata": {
        "id": "HmX6ip39PuET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "library(table1, lib.loc = pack)\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "\n",
        "t = table1(~ (SEX + BL_AGE + RACE + EDUC + factor(INCM3) + EMPL + factor(RSRC) + BL_DDX + BL_UP2 + factor(BL_COG) + factor(IS_DEP) + factor(NONCOMP) + factor(LTF))\n",
        "           , data = LTFdf, render.continuous=\"Median [Q1,Q3]\")\n",
        "\n",
        "gsub(\"\\n\", \"\", t[1])"
      ],
      "metadata": {
        "id": "JjyVXnEIlCG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Restricted Analysis for Comparison to PPMI"
      ],
      "metadata": {
        "id": "rrBA2NjL7wbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "print(\"******************MAX ENROLLMENT*****************\")\n",
        "LTFdf = fread(\"FOX_TL1_LTF24.csv\")\n",
        "LTFdf$RACE <- relevel(factor(LTFdf$RACE), ref = \"WHIT\")\n",
        "\n",
        "FIR_Y1 <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + I(BL_AGE/5) + I(RACE != \"WHIT\") + EDUC + I(BL_DDX/5) + BL_UP2 + factor(BL_COG) + IS_DEP),\n",
        "             data = filter(LTFdf, UNOS == 0))\n",
        "res = cbind(exp(coef(FIR_Y1)), exp(confint(FIR_Y1)), coef(summary(FIR_Y1))[,5])\n",
        "colnames(res) <- c(\"OR\",\"CI2.5%\",\"CI97.5%\",\"P\")\n",
        "res <- signif(res, digits=3)\n",
        "\n",
        "print(summary(FIR_Y1))\n",
        "print(res)\n",
        "print(g)"
      ],
      "metadata": {
        "id": "TfBody0W7_xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replication Timeline"
      ],
      "metadata": {
        "id": "dOXn2PN1IKy1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Return Participation"
      ],
      "metadata": {
        "id": "ouwpEIASpDoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_TL6_LTF24.csv\")\n",
        "LTFdf$RACE <- relevel(factor(LTFdf$RACE), ref = \"WHIT\")\n",
        "\n",
        "print(\"******************COMPARING ONE-TIMERS AND RETURNERS*****************\")\n",
        "RTLM_Y2 <- glm(formula = UNOS  ~ (SEX +I(BL_AGE/5) + RACE + EDUC + factor(INCM3) + EMPL  + RSRC + I(BL_DDX/5) + BL_UP2 + factor(BL_COG) + IS_DEP),\n",
        "             data = LTFdf, family = \"binomial\")\n",
        "print(summary(RTLM_Y2))"
      ],
      "metadata": {
        "id": "Yxnc6MrdIMsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nonadherence"
      ],
      "metadata": {
        "id": "RW6C1tBcpDI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"******************NONCOMPLIANCE ANALYSIS*****************\")\n",
        "NCLM_Y2 <- glm(formula = NONCOMP ~ (SEX + I(BL_AGE/5) + RACE + EDUC + factor(INCM3) + EMPL  + RSRC + I(BL_DDX/5) + BL_UP2 + factor(BL_COG) + IS_DEP),\n",
        "             data = filter(LTFdf, UNOS == 0), family = \"binomial\")\n",
        "print(summary(NCLM_Y2))\n"
      ],
      "metadata": {
        "id": "qwCaMmWvpBsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cox LTF"
      ],
      "metadata": {
        "id": "yauPhIhopKwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "print(\"******************MAX ENROLLMENT*****************\")\n",
        "LTFdf = fread(\"FOX_TL6_LTF24.csv\")\n",
        "LTFdf$RACE <- relevel(factor(LTFdf$RACE), ref = \"WHIT\")\n",
        "\n",
        "LTF_Y2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + I(BL_AGE/5) + RACE + EDUC + factor(INCM3) + EMPL + RSRC + I(BL_DDX/5) + BL_UP2 + factor(BL_COG) + IS_DEP),\n",
        "             data = filter(LTFdf, UNOS == 0))\n",
        "res = cbind(exp(coef(LTF_Y2)), exp(confint(LTF_Y2)), coef(summary(LTF_Y2))[,5])\n",
        "colnames(res) <- c(\"OR\",\"CI2.5%\",\"CI97.5%\",\"P\")\n",
        "res <- signif(res, digits=3)\n",
        "\n",
        "\n",
        "g <- ggsurvplot(fit = survfit(Surv(daysB, LTF == 1) ~ 1, data = filter(LTFdf, UNOS == 0)),\n",
        "    xlab = \"Days Since Baseline\",\n",
        "    ylab = \"Probability of Patient Remaining in Study\",\n",
        "    title = \"Likelihood of Attrition in Fox Insight Year Two\",\n",
        "    legend.title = \"\",\n",
        "    risk.table.y.text = F,\n",
        "    risk.table = TRUE)\n",
        "\n",
        "print(summary(LTF_Y2))\n",
        "print(res)\n",
        "print(g)"
      ],
      "metadata": {
        "id": "K5aS7PDEbrnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### UP2"
      ],
      "metadata": {
        "id": "1yidHzOZpNrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "print(\"******************MAX ENROLLMENT*****************\")\n",
        "LTFdf = fread(\"FOX_TL6_LTF24.csv\")\n",
        "LTFdf$RACE <- relevel(factor(LTFdf$RACE), ref = \"WHIT\")\n",
        "\n",
        "UP2_Y2 <- coxph(formula = Surv(daysB, LTF == 1) ~ UP2_SPEECH+UP2_SALIVA+UP2_CHEW+UP2_EAT+UP2_DRESS+UP2_HYGIENE+UP2_WRITE+UP2_HOBBY+UP2_SLEEP+UP2_TREMOR+UP2_UP+UP2_WALK+UP2_FREEZE,\n",
        "             data = filter(LTFdf, UNOS == 0))\n",
        "res = cbind(exp(coef(UP2_Y2)), exp(confint(UP2_Y2)), coef(summary(UP2_Y2))[,5])\n",
        "colnames(res) <- c(\"OR\",\"CI2.5%\",\"CI97.5%\",\"P\")\n",
        "res <- signif(res, digits=3)\n",
        "\n",
        "print(summary(UP2_Y2))\n",
        "print(res)"
      ],
      "metadata": {
        "id": "5wDxB3C0-L0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "library(table1, lib.loc = pack)\n",
        "\n",
        "t = table1(~ (SEX + BL_AGE + RACE + EDUC + factor(INCM3) + EMPL + factor(RSRC) + BL_DDX + BL_UP2 + factor(BL_COG) + factor(IS_DEP) + factor(NONCOMP) + factor(LTF))\n",
        "           , data = LTFdf, render.continuous=\"Median [Q1,Q3]\")\n",
        "\n",
        "gsub(\"\\n\", \"\", t[1])"
      ],
      "metadata": {
        "id": "_ILek475-h4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1st & 2nd Year Meta-Analysis"
      ],
      "metadata": {
        "id": "33cHio7lTR_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "results_fox"
      ],
      "metadata": {
        "id": "wUZc4Y6HXkUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "pack <- \"/content/gdrive/My Drive/R/packages\"\n",
        "library(metafor, lib.loc = pack)\n",
        "\n",
        "Y1_res <- c(summary(LTF_Y1)$coef[,1],summary(LTF_Y1)$coef[,3])\n",
        "Y2_res <- c(summary(LTF_Y2)$coef[,1],summary(LTF_Y2)$coef[,3])\n",
        "\n",
        "results_fox <- data.frame(rbind(Y1_res, Y2_res))\n",
        "num_vars <- (length(names(results_fox)) / 2)\n",
        "for (i in 1:(num_vars-1)){\n",
        "    model2 = rma(results_fox[[i]], sei=results_fox[[i + num_vars]], slab=c(\"Y1\",\"Y2\"), method='REML')\n",
        "    print(\"***************************\")\n",
        "    print(names(results_fox)[i])\n",
        "    print(model2)\n",
        "    print(\"HR\")\n",
        "    print(exp(model2$b))\n",
        "    print(exp(model2$ci.lb))\n",
        "    print(exp(model2$ci.ub))\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "yNIQwR0_TRaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ad-Hoc PPMI Analysis"
      ],
      "metadata": {
        "id": "H4kAIWPrR0if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loads harmonized PPMI data from GP2\n",
        "PPMI = pd.read_csv(f'{datafolder}/PPMI_GP2.csv')\n",
        "\n",
        "#Loads info on in or out status\n",
        "PS = pd.read_csv(f'{datafolder}/Participant_Status.csv')\n",
        "PS.loc[:,\"ENROLL_STATUS\"] = PS.ENROLL_STATUS.str.lower()\n",
        "\n",
        "PS = PS.loc[PS.ENROLL_STATUS.isin([\"enrolled\",\"withdrew\",\"declined\",\"complete\"])]\n",
        "\n",
        "PS.loc[:,\"ENROLL_DATE\"] = pd.to_datetime(PS.ENROLL_DATE)\n",
        "\n",
        "#Create \"Loss to Follow-Up\" Variable, then subset data\n",
        "PS.loc[:,\"censure_date\"] = (pd.to_datetime(PS.STATUS_DATE) - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1D\")\n",
        "\n",
        "PS.loc[:,\"days_to_cens\"] = (pd.to_datetime(PS.STATUS_DATE) - pd.to_datetime(PS.ENROLL_DATE)) // pd.Timedelta(\"1D\")\n",
        "PS.loc[:,\"LTF2\"] = [1 if ((s in [\"withdrew\",\"declined\"]) & (d <= 730)) else 0 for s,d in zip(PS.ENROLL_STATUS,PS.days_to_cens)]\n",
        "PS.loc[:,\"LTF5\"] = [1 if ((s in [\"withdrew\",\"declined\"]) & (d <= 1825)) else 0 for s,d in zip(PS.ENROLL_STATUS,PS.days_to_cens)]\n",
        "\n",
        "PS = PS.loc[:,[\"PATNO\",\"COHORT\",\"censure_date\",\"LTF2\",\"LTF5\"]]\n",
        "\n",
        "PPMI = PPMI.merge(PS, left_on =  \"participant_id\", right_on = \"PATNO\")\n",
        "\n",
        "PPMI = PPMI[PPMI.Phenotype.isin([\"Control\",\"PD\"])]\n",
        "\n",
        "PPMI.loc[:,\"ethrac\"] = [\"HISP\" if e == \"Hispanic or Latino\"\n",
        "                      else \"ASIA\" if r == \"Asian\"\n",
        "                      else \"BLAC\" if r == \"Black or African American\"\n",
        "                      else \"WHIT\" if r == \"White\"\n",
        "                      else \"OTH\" if r in [\"Multi-racial\",\"Other\",\"American Indian or Alaska Native\"]\n",
        "                      else np.nan for e,r in zip(PPMI.ethnicity,PPMI.race)]\n",
        "\n",
        "PPMI.loc[:,\"educlvl\"] = [\"<HS\" if yr < 12\n",
        "                         else \"HS\" if yr < 14\n",
        "                         else \"UNI\" if yr < 18\n",
        "                         else \"UNI+\" if yr >= 18\n",
        "                         else np.nan for yr in PPMI.education_years]\n",
        "\n",
        "PPMI.loc[:,\"cog3\"] = [\"DEM\" if mca < 18\n",
        "                      else \"MCI\" if mca < 26\n",
        "                      else \"NORM\" for mca in PPMI.moca_total_score]\n",
        "\n",
        "LTF = \"LTF2\"\n",
        "PPMI_cols = {\"ID\":\"participant_id\",\n",
        "              \"BL_DATE\":'date_baseline',\n",
        "              \"DATE\":'date_visit',\n",
        "              \"VM\":'visit_month',\n",
        "              \"CENS_DT\":\"censure_date\",\n",
        "              \"LTF\":LTF,\n",
        "              \"PHENO\":'Phenotype',\n",
        "              'SEX':'sex',\n",
        "              'RACE':\"ethrac\",\n",
        "              \"ETHN\":\"ethnicity\",\n",
        "              'STUDY_ARM':'study_arm',\n",
        "              'EDUC':'educlvl',\n",
        "              \"EDUCYRS\":\"education_years\",\n",
        "              \"DX_AGE\":'age_at_diagnosis',\n",
        "              'BL_AGE':'age_at_baseline',\n",
        "\n",
        "              \"UP1_COG\":\"code_upd2101_cognitive_impairment\",\n",
        "              \"UP1_PSYC\":\"code_upd2102_hallucinations_and_psychosis\",\n",
        "              \"UP1_DEP\":\"code_upd2103_depressed_mood\",\n",
        "              \"UP1_ANX\":\"code_upd2104_anxious_mood\",\n",
        "              \"UP1_APAT\":\"code_upd2105_apathy\",\n",
        "\n",
        "              \"UP2_SPEEC\": \"code_upd2201_speech\",\n",
        "              \"UP2_SALIV\":\"code_upd2202_saliva_and_drooling\",\n",
        "              \"UP2_SWALL\":\"code_upd2203_chewing_and_swallowing\",\n",
        "              \"UP2_EAT\":\"code_upd2204_eating_tasks\",\n",
        "              \"UP2_DRESS\":\"code_upd2205_dressing\",\n",
        "              \"UP2_HYGEI\":\"code_upd2206_hygiene\",\n",
        "              \"UP2_HNDWR\":\"code_upd2207_handwriting\",\n",
        "              \"UP2_HOBBY\":\"code_upd2208_doing_hobbies_and_other_activities\",\n",
        "              \"UP2_BED\":\"code_upd2209_turning_in_bed\",\n",
        "              \"UP2_TREM\":\"code_upd2210_tremor\",\n",
        "              \"UP2_GETUP\":\"code_upd2211_get_out_of_bed_car_or_deep_chair\",\n",
        "              \"UP2_WALK\":\"code_upd2212_walking_and_balance\",\n",
        "              \"UP2_FREEZ\":\"code_upd2213_freezing\",\n",
        "              \"UP2\":'mds_updrs_part_ii_summary_score',\n",
        "              \"UP3\":'mds_updrs_part_iii_summary_score',\n",
        "              \"APAT\":\"code_upd2105_apathy\",\n",
        "              \"COG\":'moca_total_score',\n",
        "              'COG3':'cog3',\n",
        "              \"DEP\":'depress_test_score',\n",
        "              \"IS_DEP\":'depress_test_score/5',\n",
        "  }\n",
        "\n",
        "\n",
        "PPMI_CS, PPMI_LNG = PrepKM(PPMI, PPMI_cols)\n",
        "\n",
        "  # PPMI_CRA = PPMI_CS.copy()\n",
        "  # PPMI_CRA.loc[:,\"CRA_MCI\"] = [1 if mca < 26 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "  # PPMI_CRA.loc[:,\"CRA_DEM\"] = [1 if mca < 18 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "  # PPMI_CRA.loc[:,\"CRA_DEP\"] = [1 if dep == 1 else 2 if ltf == 1 else 0 for dep,ltf in zip(PPMI_CS.DEP,PPMI_CS.LTF)]\n",
        "\n",
        "PPMI_CS.to_csv(f'PPMI_{LTF}_CS.csv', index=False)\n",
        "PPMI_LNG.to_csv(f'PPMI_{LTF}_LNG.csv', index=False)"
      ],
      "metadata": {
        "id": "Xl_fvL3KR3l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "PPMI_LTF2_CS <- fread(\"PPMI_LTF2_CS.csv\")\n",
        "# TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (sex + education_years + BL_AGE + BL_UP2 + BL_UP3 + BL_MCA + BL_GDS), data = filter(kd, Phenotype == \"PD\"))\n",
        "# TI_LTF <- coxph(formula = Surv(TSTART, daysB, LTF_TD == 1) ~ (EDUC + SEX + BL_AGE + BL_durdx + UP2 + UP3 + I(COG < 27) + I(DEP>4)), data = filter(PPMI_LNG, PHENO == \"PD\"))\n",
        "# print(summary(TI_LTF))\n",
        "\n",
        "PPMI2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + BL_AGE + EDUC + BL_durdx + BL_UP2 + BL_UP3 + I(BL_COG < 26) + I(BL_DEP>4)), data = filter(PPMI_LTF2_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI2))\n",
        "\n"
      ],
      "metadata": {
        "id": "KA4kZPYzS_wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tables for First Two Years Analysis"
      ],
      "metadata": {
        "id": "FUcdgsOeUGF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "LMRes <- function(model){\n",
        "  t <- coef(summary(model)) %>%\n",
        "     as.data.frame(.)\n",
        "  names(t) <- c(\"E\",\"SE\",\"Z\",\"P\")\n",
        "  t <- t %>%\n",
        "       mutate(ast = case_when(P < 0.001 ~ \"***\",\n",
        "                         P < 0.01 ~ \"**\",\n",
        "                         P < 0.05 ~ \"*\",\n",
        "                         TRUE ~ \"\"),\n",
        "              P = if_else(P<0.01, formatC(P, digits=1, format = \"e\"), as.character(round(P,2))),\n",
        "              )\n",
        "  eciLM <- round(exp(confint(model)), 2)\n",
        "  res = cbind(paste0(round(exp(coef(model)),2),\" [\",eciLM[,1],\", \",eciLM[,2],\"]\"), paste0(t[,4],t[,5])) %>%\n",
        "        as.data.frame(.)\n",
        "  colnames(res) <- c(\"ORCI\",\"P\")\n",
        "  rownames(res) <- names(model$coeff)\n",
        "  #Add spaces\n",
        "  for (i in c(4,10,15,19,26)) {\n",
        "    res = add_row(res, ORCI = \" \", P = \" \", .before = i)\n",
        "    res = add_row(res, ORCI = \"-\", P = \"-\", .before = i + 1)\n",
        "  }\n",
        "  res <- res[-1,]\n",
        "  rownames(res) <- NULL\n",
        "  return(res)\n",
        "}\n",
        "res1 = LMRes(RTLM_Y1)\n",
        "res2 = LMRes(RTLM_Y2)\n",
        "res = cbind(res1,res2)\n",
        "names(res) <- c(\"ORCI_Y1\",\"P1\",\"ORCI_Y2\",\"P2\")\n",
        "kable(res,\"html\")"
      ],
      "metadata": {
        "id": "N_ey8rxZUHtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "res1 = LMRes(NCLM_Y1)\n",
        "res2 = LMRes(NCLM_Y2)\n",
        "res = cbind(res1,res2)\n",
        "\n",
        "kable(res,\"html\")"
      ],
      "metadata": {
        "id": "pzq3ldyUmq3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "CPHRes <- function(model, spaces = TRUE, rows = FALSE) {\n",
        "  t <- coef(summary(model))[,5] %>%\n",
        "     as.data.frame(.)\n",
        "  names(t) <- c(\"P\")\n",
        "  t <- t %>%\n",
        "       mutate(ast = case_when(P < 0.001 ~ \"***\",\n",
        "                         P < 0.01 ~ \"**\",\n",
        "                         P < 0.05 ~ \"*\",\n",
        "                         TRUE ~ \"\"),\n",
        "              P = if_else(P<0.01, formatC(P, digits=2, format = \"e\"), as.character(round(P,2))),\n",
        "              )\n",
        "  eciLM <- round(exp(confint(model)), 2)\n",
        "  res = cbind(paste0(round(exp(coef(model)),2),\" [\",eciLM[,1],\", \",eciLM[,2],\"]\"), paste0(t[,1],t[,2])) %>%\n",
        "        as.data.frame(.)\n",
        "  colnames(res) <- c(\"ORCI\",\"P\")\n",
        "\n",
        "  eciLM <- round(exp(confint(model)), 2)\n",
        "  if (!rows) {\n",
        "    rownames(res) <- NULL\n",
        "  } else {\n",
        "    rownames(res) <- names(model$coef)\n",
        "  }\n",
        "  #Add spaces\n",
        "  if (spaces){\n",
        "    for (i in c(3,9,14,18,25)) {\n",
        "      res = add_row(res, ORCI = \" \", P = \" \", .before = i)\n",
        "      res = add_row(res, ORCI = \"-\", P = \"-\", .before = i + 1)\n",
        "    }\n",
        "  }\n",
        "\n",
        "  return(res)\n",
        "}\n",
        "\n",
        "res1 = CPHRes(LTF_Y1,rows=F)\n",
        "res2 = CPHRes(LTF_Y2)\n",
        "res = cbind(res1,res2)\n",
        "kable(res,\"html\")\n"
      ],
      "metadata": {
        "id": "mPyf4cK-ulHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "res1 = CPHRes(UP2_Y1,spaces=F,rows=F)\n",
        "res2 = CPHRes(UP2_Y2,spaces=F,rows=F)\n",
        "res = cbind(res1,res2)\n",
        "kable(res,\"html\")"
      ],
      "metadata": {
        "id": "GShund6r-UYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different Timelines"
      ],
      "metadata": {
        "id": "-B2KdUKQbjzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "round(LTF$coef, 3)"
      ],
      "metadata": {
        "id": "ELqZXAYZWq3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "LTFdf_t <- mutate(LTFdf, BL_UP2 = if_else(BL_UP2 > 25, 0, 1)) #BL_AGE = round(BL_AGE, -1), BL_DDX = round(BL_DDX, -1), )\n",
        "covars <- c(\"SEX\", \"RACE\", \"EDUC\", \"INCM\", \"RSRC\", \"EMPL\", \"BL_UP2\", \"BL_MCI\", \"IS_DEP\")\n",
        "\n",
        "for (i in 1:length(covars)){\n",
        "  survltf <- eval(parse(text = paste(\"survfit(Surv(daysB, LTF == 1) ~ \",covars[i],\", data = LTFdf_t)\")))\n",
        "  g <- ggsurvplot(fit = survltf,\n",
        "      xlab = \"Days Since Baseline\",\n",
        "      ylab = \"Probability of Patient Remaining in Study\",\n",
        "      title = \"Likelihood of Attrition in Fox Insight\",\n",
        "      legend.title = \"\",\n",
        "      risk.table.y.text = F,\n",
        "      risk.table = TRUE\n",
        "      )\n",
        "\n",
        "  print(g)\n",
        "}"
      ],
      "metadata": {
        "id": "ijPC4TH5fuBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_TL2_LTF48.csv\")\n",
        "\n",
        "print(\"******************PRE COVID*****************\")\n",
        "\n",
        "LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + BL_AGE + RACE + EDUC + INCM + RSRC + EMPL + BL_DDX + BL_UP2 + BL_MCI + IS_DEP),\n",
        "             data = LTFdf)\n",
        "print(summary(LTF))"
      ],
      "metadata": {
        "id": "d3XnMtXHqeHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_TL3_LTF12.csv\")\n",
        "\n",
        "print(\"******************COVID FU*****************\")\n",
        "\n",
        "LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + BL_AGE + RACE + EDUC + INCM + RSRC + EMPL + BL_DDX + BL_UP2 + BL_MCI + IS_DEP),\n",
        "             data = LTFdf)\n",
        "print(summary(LTF))"
      ],
      "metadata": {
        "id": "dr08Py7HqeBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_TL4_LTF12.csv\")\n",
        "\n",
        "print(\"******************COVID RECRUITMENT*****************\")\n",
        "\n",
        "LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + BL_AGE + RACE + EDUC + INCM + RSRC + EMPL + BL_DDX + BL_UP2 + BL_MCI + IS_DEP),\n",
        "             data = LTFdf)\n",
        "print(summary(LTF))"
      ],
      "metadata": {
        "id": "0fJt2dm1qd7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_TL5_LTF15.csv\")\n",
        "\n",
        "print(\"******************POST TIME WINDOW CHANGE*****************\")\n",
        "\n",
        "LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + BL_AGE + RACE + EDUC + INCM + RSRC + EMPL + BL_DDX + BL_UP2 + BL_MCI + IS_DEP),\n",
        "             data = LTFdf)\n",
        "print(summary(LTF))"
      ],
      "metadata": {
        "id": "sgkdA8bRqdqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create test dataset for attrition"
      ],
      "metadata": {
        "id": "Lx5b-g8dTy0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# According to Yasir and Josh, ReturnPD visits are assigned at each expected visit,\n",
        "# We can use this to determine how long a participant was in the study\n",
        "\n",
        "#Load return PD data\n",
        "RPD = pd.read_csv(f\"{datafolder}/FOX/ReturnPD.csv\")\n",
        "\n",
        "#Identify how old the participant would have been at the last expected visit\n",
        "lastage = RPD.pivot_table(index=\"fox_insight_id\", values = \"age\", aggfunc = \"max\")\n",
        "\n",
        "#Age at enrollment is collected from Users data\n",
        "U = (pd.read_csv(f\"{datafolder}/FOX/Users.csv\")\n",
        "        .set_index(\"fox_insight_id\")\n",
        "        .rename({\"AgeAtEnrollment\":\"BL_age\"},axis=1)\n",
        "        .loc[:,\"BL_age\"])\n",
        "\n",
        "#Create follow-up time based on lastest age and enrollment age\n",
        "FU = pd.concat([U, lastage],axis=1).dropna()\n",
        "FU.loc[:,\"FUTIME\"] = ((FU.age - FU.BL_age) * 12).round(0)\n",
        "\n",
        "#Estimate enrollment date based on date of data pull, follow-up time, and time window of 3 months\n",
        "dts = [dt.datetime.today() - dt.timedelta(weeks = fu * 4) for fu in FU.FUTIME]\n",
        "\n",
        "FU.loc[:,\"earliest_enroll_dt\"] = [f\"{(date - dt.timedelta(weeks = 12)).month}/{date.year}\" for date in dts]\n",
        "\n",
        "FU.loc[:,\"lastest_enroll_dt\"] = [f\"{dt.month}/{dt.year}\" for dt in dts]\n",
        "\n",
        "FU.loc[:,\"est_enroll_dt\"] = [date.date() for date in dts]\n",
        "\n",
        "#Using data from GP2 harmonization, we can determine which participants have recently completed surveys\n",
        "ACT = (pd.read_csv(f\"{datafolder}/FOX/FOX_processed.csv\")\n",
        "        .pivot_table(index=\"participant_id\", values = \"visit_month\", aggfunc = \"max\"))\n",
        "\n",
        "FU = FU.join(ACT)\n",
        "\n",
        "FU.loc[:,\"INACT\"] = FU.FUTIME - FU.visit_month\n",
        "\n",
        "#Participants with INACT less than zero have changes to diagnosis status\n",
        "print(f\"{FU[FU.INACT < 0].index.nunique()} participants pruned due to negative inactive time\")\n",
        "FU = FU[FU.INACT > 0]"
      ],
      "metadata": {
        "id": "ZoO7uQAd3GMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{FU.index.nunique()} participants\")\n",
        "px.histogram(FU.est_enroll_dt)"
      ],
      "metadata": {
        "id": "3WlpZ4mEN7Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What year-long enrollment period collects the most participants?\n",
        "max = 0\n",
        "for year in [2016,2017,2018,2019]:\n",
        "  for month in range(1,13):\n",
        "    n = ((dt.datetime(year=year,month=month,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=year+1, month=month,day = 1))).sum()\n",
        "    if n > max:\n",
        "      print(f\"The new max enroll start date is {month}/{year} with {n} participants\")\n",
        "      max = n"
      ],
      "metadata": {
        "id": "LdOzpBdGKYYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enroll_dts = pd.to_datetime(FU.est_enroll_dt)\n",
        "\n",
        "\n",
        "tl1 = ((dt.datetime(year=2018,month=4,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2019, month=4,day = 1)))\n",
        "print(f'{tl1.sum()} participants in max enroll timeline')\n",
        "tl2 = ((dt.datetime(year=2017,month=10,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2018, month=10,day = 1)))\n",
        "print(f'{tl2.sum()} participants in pre-COVID timeline')\n",
        "tl3 = ((dt.datetime(year=2018,month=3,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2019, month=3,day = 1)))\n",
        "print(f'{tl3.sum()} participants in COVID follow-up timeline')\n",
        "tl4 = ((dt.datetime(year=2019,month=3,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2020, month=3,day = 1)))\n",
        "print(f'{tl4.sum()} participants in COVID recruitment timeline')\n",
        "tl5 = ((dt.datetime(year=2019,month=9,day=1) < enroll_dts) & (enroll_dts < dt.datetime(year=2020, month=9,day = 1)))\n",
        "print(f'{tl5.sum()} participants in post time window change timeline')\n",
        "\n"
      ],
      "metadata": {
        "id": "xEpxpL9qaimY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for thresh in range(3,24,3):\n",
        "  print(f\"{((FU.INACT > thresh).sum() / len(FU.INACT) * 100).round(2)} percent attrition with threshold of {thresh}\")\n",
        "px.histogram(FU.INACT)"
      ],
      "metadata": {
        "id": "MMnpUjWN4KeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FU.loc[:,\"ACT\"] = [fu - ina if ina > 12 else np.nan for fu, ina in zip(FU.FUTIME,FU.INACT)]\n",
        "FU.loc[:,\"drop_dt\"] = FU.est_enroll_dt + (FU.ACT * 4)\n",
        "\n",
        "FU"
      ],
      "metadata": {
        "id": "XmwKI1st-f_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test create dataset for LTF analysis\n",
        "# Set parameters\n",
        "## Load FOX only once to reduce processing time\n",
        "# FOX = pd.read_csv(f'{datafolder}/FOX/FOX_processed.csv')\n",
        "## Set timeline of interest\n",
        "tl = tl2[tl2].copy()\n",
        "tln = \"TL2\"\n",
        "FUP = 24\n",
        "\n",
        "#Previous runs\n",
        "# TL1/24\n",
        "# TL5/15562\n",
        "\n",
        "#Create dataframe with only timeline participants with two year follow-up\n",
        "## Subset FOX dataset\n",
        "FOX1 = FOX[FOX.participant_id.isin(tl.index)]\n",
        "\n",
        "## Round visit_month down to visit window start\n",
        "FOX1.insert(loc=1,column = \"VM\", value = (FOX1.visit_month // 3) * 3)\n",
        "FOX1.insert(loc=1, column = \"daysB\", value = (FOX1.visit_month * 30))\n",
        "\n",
        "## Drop visit_months greater than 24 months\n",
        "FOX1 = FOX1[FOX1.VM <= FUP]\n",
        "\n",
        "print(f\"{FOX1.participant_id.nunique()} participants before cleaning\")\n",
        "\n",
        "FOX1 = FOX1.set_index(\"participant_id\")\n",
        "\n",
        "BL_cols = [\"mds_updrs_part_ii_summary_score\",\"gds15_total_score\"]\n",
        "\n",
        "for col in BL_cols:\n",
        "  FOXt = FOX1[~FOX1.index.duplicated(keep=\"first\")].loc[:,col]\n",
        "  FOXt.name = f\"BL_{col.upper().split('_')[0]}\"\n",
        "  FOX1 = FOX1.join(FOXt)\n",
        "\n",
        "FOX2 = FOX1[~FOX1.index.duplicated(keep=\"last\")]\n",
        "\n",
        "#Create additional variables\n",
        "FOX2.loc[:,\"education_years\"] = FOX2.education_level.map({'High School/GED':0, 'Some college without degree':0,\n",
        "       'Professional or doctoral degree':1, \"Master's degree\":1, \"Bachelor's degree\":1,\n",
        "       'Associate degree college':1, '<High School':0})\n",
        "\n",
        "FOX2.loc[:,\"BL_durdx\"] = FOX2.age_at_baseline - FOX2.age_at_diagnosis\n",
        "\n",
        "cov = [\"daysB\",\"visit_month\",\"age_at_baseline\",\"age_at_diagnosis\",\"BL_durdx\",\"sex\",\"education_years\",\"race\",\"BL_MDS\",\"BL_GDS15\"]\n",
        "\n",
        "for col in cov:\n",
        "  print(f\"{FOX2.loc[:,col].isna().sum()} participants removed due to {col}\")\n",
        "  FOX2 = FOX2.dropna(subset = [col])\n",
        "\n",
        "FOX2 = FOX2.loc[:,cov]\n",
        "\n",
        "print(f\"{FOX2.index.nunique()} participants after cleaning\")\n",
        "\n",
        "FOX2.loc[:,\"LTF\"] = [1 if vm < FUP else 0 for vm in FOX2.visit_month]\n",
        "\n",
        "FOX2.to_csv(f\"FOX_LTF{FUP}_{tln}.csv\",index=False)\n",
        "FOX2"
      ],
      "metadata": {
        "id": "p7YeNYTZPYdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_LTF24_TL2.csv\")\n",
        "\n",
        "print(\"******************ST COXPH*****************\")\n",
        "\n",
        "LTF <- coxph(formula = Surv(visit_month, LTF == 1) ~ (sex + education_years + age_at_baseline + BL_durdx\n",
        "                                                      + BL_MDS + BL_GDS15), data = LTFdf)\n",
        "print(summary(LTF))"
      ],
      "metadata": {
        "id": "5YeKoXUuaSr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "#Loads dataset created in python\n",
        "LTFdf = fread(\"FOX_LTF15_TL5.csv\")\n",
        "\n",
        "print(\"******************ST COXPH*****************\")\n",
        "\n",
        "LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (sex + education_years + age_at_baseline + BL_durdx\n",
        "                                                      + BL_MDS + BL_GDS15), data = LTFdf)\n",
        "print(summary(LTF))"
      ],
      "metadata": {
        "id": "Qf4HwRSh-AEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOX = pd.read_csv(f'{datafolder}/FOX/FOX_processed.csv')\n",
        "FOX.insert(loc=1, column = \"previous_vm\", value = FOX.groupby(\"participant_id\").shift(1).loc[:,\"visit_month\"])\n",
        "FOX.insert(loc=1, column = \"SOA\", value = [(vm // 3) * 3 for vm in FOX.visit_month])\n",
        "FOX = FOX.drop_duplicates(subset = [\"participant_id\",\"SOA\"])\n",
        "#.pivot(index=\"participant_id\", columns = \"visit_month\")\n",
        "px.histogram(FOX.visit_month, x = \"visit_month\")"
      ],
      "metadata": {
        "id": "JsHBTKHmT5x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOX_count = FOX.pivot_table(index=\"participant_id\",values = \"visit_month\",aggfunc=\"count\").rename({\"visit_month\":\"visit_count\"}, axis=1)\n",
        "px.histogram(FOX_count, x = \"visit_count\")"
      ],
      "metadata": {
        "id": "SuXSkAXMVtm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOX_lastvm = (FOX.drop_duplicates(subset = \"participant_id\",keep=\"last\")\n",
        "                 .loc[:,[\"participant_id\",\"SOA\"]]\n",
        "                 .rename({\"SOA\":\"LastVM\"},axis=1)\n",
        "                 .set_index(\"participant_id\"))\n",
        "\n",
        "FOX_freq = FOX_count.join(FOX_lastvm)\n",
        "\n",
        "FOX_freq.loc[:,\"freq\"] = (FOX_freq.LastVM / FOX_freq.visit_count).round(1)\n",
        "\n",
        "px.histogram(FOX_freq, x=\"freq\")"
      ],
      "metadata": {
        "id": "sQChtGxQWL-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOX2 = FOX_lastvm[FOX_lastvm.LastVM >= 24].index\n",
        "FOX2_df = FOX[(FOX.participant_id.isin(FOX2)) & (FOX.SOA <= 24)]\n",
        "px.histogram(FOX2_df.pivot_table(index=\"participant_id\", values = \"SOA\", aggfunc = \"count\") / .09, x= \"SOA\", labels = {\"SOA\":\"Compliance Rate\"})\n",
        "#Expected visits [BL, 3, 6, 9, 12, 15, 18, 21, 24] = 9"
      ],
      "metadata": {
        "id": "LjxYE9UBiBGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOX2_df.iloc[0:50,51:100]"
      ],
      "metadata": {
        "id": "4bPScr9BoVsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOX = pd.read_csv(f'{datafolder}/FOX/FOX_processed.csv')\n",
        "FOX_UP2 = FOX.pivot_table(index=\"participant_id\",values = \"mds_updrs_part_ii_summary_score\", aggfunc=\"count\")\n",
        "FOX_UP2.columns = [\"UP2\"]\n",
        "\n",
        "px.histogram(FOX_UP2)"
      ],
      "metadata": {
        "id": "la_1gQmiAEVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U = pd.read_csv(f'{datafolder}/FOX/Users.csv')\n",
        "U_cols = {\"fox_insight_id\":\"ID\",\n",
        "              \"AgeAtEnrollment\":\"BL_AGE\",\n",
        "              \"days_elapsed\":\"BL_DATE\",\n",
        "              \"InitPDDiagAge\":\"DX_AGE\",\n",
        "             }\n",
        "\n",
        "U = U.rename(U_cols, axis=1).loc[:,U_cols.values()]\n",
        "\n",
        "U.loc[:,\"BL_durdx\"] = U.BL_AGE - U.DX_AGE\n",
        "\n",
        "BMS_cols =  {\"fox_insight_id\":\"ID\",\n",
        "              \"AgeAtEnrollment\":\"BL_AGE\",\n",
        "              \"days_elapsed\":\"BL_DATE\",\n",
        "              \"InitPDDiagAge\":\"DX_AGE\",\n",
        "             }\n",
        "\n",
        "BMS = pd.read_csv(f'{datafolder}/FOX/Brief_Motor_Screen.csv')\n",
        "BMS.sort_values([\"fox_insight_id\",\"days_elapsed\"]).head(50)"
      ],
      "metadata": {
        "id": "RQCxA3kdyTJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNd78Gsc_-Ub"
      },
      "source": [
        "# PPMI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loads harmonized PPMI data from GP2\n",
        "PPMI = pd.read_csv(f'{datafolder}/PPMI_GP2.csv')\n",
        "\n",
        "#Loads info on in or out status\n",
        "PS = pd.read_csv(f'{datafolder}/Participant_Status.csv')\n",
        "PS.loc[:,\"ENROLL_STATUS\"] = PS.ENROLL_STATUS.str.lower()\n",
        "\n",
        "PS = PS.loc[PS.ENROLL_STATUS.isin([\"enrolled\",\"withdrew\",\"declined\",\"complete\"])]\n",
        "\n",
        "PS.loc[:,\"ENROLL_DATE\"] = pd.to_datetime(PS.ENROLL_DATE)\n",
        "\n",
        "#Create \"Loss to Follow-Up\" Variable, then subset data\n",
        "PS.loc[:,\"censure_date\"] = (pd.to_datetime(PS.STATUS_DATE) - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1D\")\n",
        "\n",
        "PS.loc[:,\"days_to_cens\"] = (pd.to_datetime(PS.STATUS_DATE) - pd.to_datetime(PS.ENROLL_DATE)) // pd.Timedelta(\"1D\")\n",
        "PS.loc[:,\"LTF2\"] = [1 if ((s in [\"withdrew\",\"declined\"]) & (d <= 730)) else 0 for s,d in zip(PS.ENROLL_STATUS,PS.days_to_cens)]\n",
        "PS.loc[:,\"LTF5\"] = [1 if ((s in [\"withdrew\",\"declined\"]) & (d <= 1825)) else 0 for s,d in zip(PS.ENROLL_STATUS,PS.days_to_cens)]\n",
        "\n",
        "PS = PS.loc[:,[\"PATNO\",\"COHORT\",\"censure_date\",\"LTF2\",\"LTF5\"]]\n",
        "\n",
        "PPMI = PPMI.merge(PS, left_on =  \"participant_id\", right_on = \"PATNO\")\n",
        "\n",
        "PPMI = PPMI[PPMI.Phenotype.isin([\"Control\",\"PD\"])]\n",
        "\n",
        "PPMI.loc[:,\"ethrac\"] = [\"HISP\" if e == \"Hispanic or Latino\"\n",
        "                      else \"ASIA\" if r == \"Asian\"\n",
        "                      else \"BLAC\" if r == \"Black or African American\"\n",
        "                      else \"WHIT\" if r == \"White\"\n",
        "                      else \"OTH\" if r in [\"Multi-racial\",\"Other\",\"American Indian or Alaska Native\"]\n",
        "                      else np.nan for e,r in zip(PPMI.ethnicity,PPMI.race)]\n",
        "\n",
        "PPMI.loc[:,\"educlvl\"] = [\"<HS\" if yr < 12\n",
        "                         else \"HS\" if yr < 14\n",
        "                         else \"UNI\" if yr < 18\n",
        "                         else \"UNI+\" if yr >= 18\n",
        "                         else np.nan for yr in PPMI.education_years]\n",
        "\n",
        "PPMI.loc[:,\"cog3\"] = [\"DEM\" if mca < 18\n",
        "                      else \"MCI\" if mca < 26\n",
        "                      else \"NORM\" for mca in PPMI.moca_total_score]\n",
        "\n",
        "for LTF in [\"LTF2\",\"LTF5\"]:\n",
        "  PPMI_cols = {\"ID\":\"participant_id\",\n",
        "              \"BL_DATE\":'date_baseline',\n",
        "              \"DATE\":'date_visit',\n",
        "              \"VM\":'visit_month',\n",
        "              \"CENS_DT\":\"censure_date\",\n",
        "              \"LTF\":LTF,\n",
        "              \"PHENO\":'Phenotype',\n",
        "              'SEX':'sex',\n",
        "              'RACE':\"ethrac\",\n",
        "              \"ETHN\":\"ethnicity\",\n",
        "              'STUDY_ARM':'study_arm',\n",
        "              'EDUC':'educlvl',\n",
        "              \"DX_AGE\":'age_at_diagnosis',\n",
        "              'BL_AGE':'age_at_baseline',\n",
        "\n",
        "              \"UP1_COG\":\"code_upd2101_cognitive_impairment\",\n",
        "              \"UP1_PSYC\":\"code_upd2102_hallucinations_and_psychosis\",\n",
        "              \"UP1_DEP\":\"code_upd2103_depressed_mood\",\n",
        "              \"UP1_ANX\":\"code_upd2104_anxious_mood\",\n",
        "              \"UP1_APAT\":\"code_upd2105_apathy\",\n",
        "\n",
        "              \"UP2_SPEEC\": \"code_upd2201_speech\",\n",
        "              \"UP2_SALIV\":\"code_upd2202_saliva_and_drooling\",\n",
        "              \"UP2_SWALL\":\"code_upd2203_chewing_and_swallowing\",\n",
        "              \"UP2_EAT\":\"code_upd2204_eating_tasks\",\n",
        "              \"UP2_DRESS\":\"code_upd2205_dressing\",\n",
        "              \"UP2_HYGEI\":\"code_upd2206_hygiene\",\n",
        "              \"UP2_HNDWR\":\"code_upd2207_handwriting\",\n",
        "              \"UP2_HOBBY\":\"code_upd2208_doing_hobbies_and_other_activities\",\n",
        "              \"UP2_BED\":\"code_upd2209_turning_in_bed\",\n",
        "              \"UP2_TREM\":\"code_upd2210_tremor\",\n",
        "              \"UP2_GETUP\":\"code_upd2211_get_out_of_bed_car_or_deep_chair\",\n",
        "              \"UP2_WALK\":\"code_upd2212_walking_and_balance\",\n",
        "              \"UP2_FREEZ\":\"code_upd2213_freezing\",\n",
        "              \"UP2\":'mds_updrs_part_ii_summary_score',\n",
        "              \"UP3\":'mds_updrs_part_iii_summary_score',\n",
        "              \"APAT\":\"code_upd2105_apathy\",\n",
        "              \"COG\":'moca_total_score',\n",
        "              'COG3':'cog3',\n",
        "              \"DEP\":'depress_test_score',\n",
        "              \"IS_DEP\":'depress_test_score/5',\n",
        "  }\n",
        "\n",
        "\n",
        "  PPMI_CS, PPMI_LNG = PrepKM(PPMI, PPMI_cols)\n",
        "\n",
        "  # PPMI_CRA = PPMI_CS.copy()\n",
        "  # PPMI_CRA.loc[:,\"CRA_MCI\"] = [1 if mca < 26 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "  # PPMI_CRA.loc[:,\"CRA_DEM\"] = [1 if mca < 18 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "  # PPMI_CRA.loc[:,\"CRA_DEP\"] = [1 if dep == 1 else 2 if ltf == 1 else 0 for dep,ltf in zip(PPMI_CS.DEP,PPMI_CS.LTF)]\n",
        "\n",
        "  PPMI_CS.to_csv(f'PPMI_{LTF}_CS.csv', index=False)\n",
        "  PPMI_LNG.to_csv(f'PPMI_{LTF}_LNG.csv', index=False)"
      ],
      "metadata": {
        "id": "80ztSATcWn67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhLoBYJXVXqh"
      },
      "source": [
        "## Two Year LTF Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-eN84VDbm7j"
      },
      "source": [
        "%%R\n",
        "PPMI_LTF2_CS <- fread(\"PPMI_LTF2_CS.csv\")\n",
        "# TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (sex + education_years + BL_AGE + BL_UP2 + BL_UP3 + BL_MCA + BL_GDS), data = filter(kd, Phenotype == \"PD\"))\n",
        "# TI_LTF <- coxph(formula = Surv(TSTART, daysB, LTF_TD == 1) ~ (EDUC + SEX + BL_AGE + BL_durdx + UP2 + UP3 + I(COG < 27) + I(DEP>4)), data = filter(PPMI_LNG, PHENO == \"PD\"))\n",
        "# print(summary(TI_LTF))\n",
        "\n",
        "PPMI2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX + BL_AGE + EDUC + BL_durdx + BL_UP2 + BL_UP3 + I(BL_COG < 26) + I(BL_DEP>4)), data = filter(PPMI_LTF2_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI2))\n",
        "\n",
        "PPMI2M <- coxph(formula = Surv(daysB, LTF == 1) ~ (BL_UP2_SPEEC + BL_UP2_SALIV +\n",
        "        BL_UP2_SWALL + BL_UP2_EAT + BL_UP2_DRESS + BL_UP2_HYGEI + BL_UP2_HNDWR + BL_UP2_HOBBY + BL_UP2_BED\n",
        "        + BL_UP2_TREM + BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_FREEZ), data = filter(PPMI_LTF2_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI2M))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "CPHRes <- function(model, spaces = TRUE, rows = FALSE) {\n",
        "  t <- coef(summary(model))[,5] %>%\n",
        "     as.data.frame(.)\n",
        "  names(t) <- c(\"P\")\n",
        "  t <- t %>%\n",
        "       mutate(ast = case_when(P < 0.001 ~ \"***\",\n",
        "                         P < 0.01 ~ \"**\",\n",
        "                         P < 0.05 ~ \"*\",\n",
        "                         TRUE ~ \"\"),\n",
        "              P = if_else(P<0.01, formatC(P, digits=2, format = \"e\"), as.character(round(P,2))),\n",
        "              )\n",
        "  eciLM <- round(exp(confint(model)), 2)\n",
        "  res = cbind(paste0(round(exp(coef(model)),2),\" [\",eciLM[,1],\", \",eciLM[,2],\"]\"), paste0(t[,1],t[,2])) %>%\n",
        "        as.data.frame(.)\n",
        "  colnames(res) <- c(\"ORCI\",\"P\")\n",
        "\n",
        "  eciLM <- round(exp(confint(model)), 2)\n",
        "  #Add spaces\n",
        "  if (spaces){\n",
        "    for (i in c(3,9,14,22)) {\n",
        "      res = add_row(res, ORCI = \" \", P = \" \", .before = i)\n",
        "      res = add_row(res, ORCI = \"-\", P = \"-\", .before = i + 1)\n",
        "    }\n",
        "  }\n",
        "  if (!rows) {\n",
        "    rownames(res) <- NULL\n",
        "  }\n",
        "  return(res)\n",
        "}\n",
        "\n",
        "res <- CPHRes(PPMI2M, spaces=FALSE)\n",
        "kable(res,\"html\")"
      ],
      "metadata": {
        "id": "7xo7yhrcRYJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Five Year LTF Analysis"
      ],
      "metadata": {
        "id": "JGfEWHFZcsgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "PPMI_LTF5_CS <- fread(\"PPMI_LTF5_CS.csv\")\n",
        "# TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (sex + education_years + BL_AGE + BL_UP2 + BL_UP3 + BL_MCA + BL_GDS), data = filter(kd, Phenotype == \"PD\"))\n",
        "# TI_LTF <- coxph(formula = Surv(TSTART, daysB, LTF_TD == 1) ~ (EDUC + SEX + BL_AGE + BL_durdx + UP2 + UP3 + I(COG < 27) + I(DEP>4)), data = filter(PPMI_LNG, PHENO == \"PD\"))\n",
        "# print(summary(TI_LTF))\n",
        "\n",
        "PPMI5 <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX + BL_AGE + BL_durdx + BL_UP2 + BL_UP3 + I(BL_COG < 27) + I(BL_DEP>4)), data = filter(PPMI_LTF5_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI5))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jEEKS-aZco9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item-Level UP2 Analysis"
      ],
      "metadata": {
        "id": "lcITgrri3ciJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "PPMI2UP2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (BL_UP2_SPEEC + BL_UP2_SALIV +\n",
        "        BL_UP2_SWALL + BL_UP2_EAT + BL_UP2_DRESS + BL_UP2_HYGEI + BL_UP2_HNDWR + BL_UP2_HOBBY + BL_UP2_BED\n",
        "        + BL_UP2_TREM + BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_FREEZ), data = filter(PPMI_LTF2_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI2UP2))\n",
        "\n",
        "PPMI5UP2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (BL_UP2_SPEEC + BL_UP2_SALIV +\n",
        "        BL_UP2_SWALL + BL_UP2_EAT + BL_UP2_DRESS + BL_UP2_HYGEI + BL_UP2_HNDWR + BL_UP2_HOBBY + BL_UP2_BED\n",
        "        + BL_UP2_TREM + BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_FREEZ), data = filter(PPMI_LTF5_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI5UP2))"
      ],
      "metadata": {
        "id": "6qnL5D0nlIJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "kable(CPHRes(PPMI2UP2,spaces=F))"
      ],
      "metadata": {
        "id": "gE9CmNxeSSU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mobility Measure Test"
      ],
      "metadata": {
        "id": "z8wqlhi43gZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "\n",
        "PPMI_LTF2_CS <- mutate(PPMI_LTF2_CS, BL_UP2_MOB = BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_DRESS)\n",
        "PPMI_LTF5_CS <- mutate(PPMI_LTF5_CS, BL_UP2_MOB = BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_DRESS)\n",
        "\n",
        "PPMI2M <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX + BL_AGE + BL_durdx + BL_UP2_MOB + BL_UP3 + I(BL_COG < 27) + I(BL_DEP>4)), data = filter(PPMI_LTF2_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI2M))\n",
        "\n",
        "PPMI5M <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX + BL_AGE + BL_durdx + BL_UP2_MOB + BL_UP3 + I(BL_COG < 27) + I(BL_DEP>4)), data = filter(PPMI_LTF5_CS, PHENO == \"PD\"))\n",
        "print(summary(PPMI5M))"
      ],
      "metadata": {
        "id": "XMEHFO2koJGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHMPlMNgdRko"
      },
      "source": [
        "# NET-PD-LS1 Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbniIedwyZmU"
      },
      "source": [
        "LS1 = pd.read_csv(f'{datafolder}/LS1_processed.csv')\n",
        "LS1d = pd.read_csv(f'{datafolder}/LS1_demo.csv').loc[:,[\"SUBJID\",\"occmosty\",\"occcurry\"]]\n",
        "LS1s = pd.read_csv(f'{datafolder}/LS1_status.csv').loc[:,[\"SUBJID\",\"term\",\"days_term\"]].merge(LS1d, how = \"left\")\n",
        "LS1s.loc[:,\"term\"] = LS1s.term.fillna(0)\n",
        "\n",
        "LS1 = LS1.merge(LS1s, how = \"left\", left_on = \"participant_id\", right_on  = \"SUBJID\")\n",
        "\n",
        "LS1.loc[:,\"mds_updrs_part_ii_summary_score\"] = ((LS1.updrs_part_ii_summary_score * 1.1) + 0.2)\n",
        "LS1.loc[:,\"mds_updrs_part_iii_summary_score\"] = ((LS1.updrs_part_iii_summary_score * 1.2) + 2.3)\n",
        "\n",
        "# LS1_LTF = LS1.pivot_table(index=\"participant_id\", values = \"visit_month\", aggfunc = \"max\")\n",
        "# LS1_LTF.loc[:,\"LTF_TI\"] = [0 if i >= 60 else 1 for i in LS1_LTF.iloc[:,0]]\n",
        "# LS1_LTF.columns = [\"LTF_VM\",\"LTF\"]\n",
        "\n",
        "# LS1_LTF = LS1_LTF.reset_index()\n",
        "\n",
        "# LS1 = LS1.merge(LS1_LTF)\n",
        "\n",
        "LS1.loc[:,\"education_years\"] = LS1.education_level.map({'High School/GED':0, 'Some college without degree':0,\n",
        "       'Professional or doctoral degree':1, \"Bachelor's degree\":1,\n",
        "       'Associate degree college':1, '<High School':0})\n",
        "LS1 = LS1.rename({\"term\":\"LTF5\"},axis=1)\n",
        "LS1.loc[:,\"LTF2\"] = [1 if ((t==1) & (dt >= 730)) else  0 for t,dt in zip(LS1.LTF5, LS1.days_term)]\n",
        "LS1.loc[:,\"LTF5\"] = LS1.LTF5.mask(LS1.LTF2 == 1, np.nan)\n",
        "\n",
        "for LTF in [\"LTF2\",\"LTF5\"]:\n",
        "  ls1_dict = {\"ID\":'participant_id',\n",
        "              \"BL_DATE\":'date_baseline',\n",
        "              \"DATE\":'date_visit',\n",
        "              \"VM\":'visit_month',\n",
        "              \"CENS_DT\":\"days_term\",\n",
        "              \"LTF\":LTF,\n",
        "              \"PHENO\":'Phenotype',\n",
        "              \"SEX\":'sex',\n",
        "              \"EDUC\":\"education_years\",\n",
        "              \"RACE\":\"race\",\n",
        "              \"OCCMOST\":\"occmosty\",\n",
        "              \"ARM\":'study_arm',\n",
        "              \"DX_AGE\":'age_at_diagnosis',\n",
        "              \"BL_AGE\":'age_at_baseline',\n",
        "\n",
        "              \"UP1_COG\":\"code_upd101_intellectual_impairment\",\n",
        "              \"UP1_PSYC\":\"code_upd102_thought_disorder\",\n",
        "              \"UP1_DEP\":\"code_upd103_depression\",\n",
        "              \"UP1_APAT\":\"code_upd104_motivation\",\n",
        "\n",
        "              \"UP2_SPEEC\": \"code_upd105_speech\",\n",
        "              \"UP2_SALIV\":\"code_upd106_salivation\",\n",
        "              \"UP2_SWALL\":\"code_upd107_swallowing\",\n",
        "              \"UP2_EAT\":\"code_upd109_eating_tasks\",\n",
        "              \"UP2_DRESS\":\"code_upd110_dressing\",\n",
        "              \"UP2_HYGEI\":\"code_upd111_hygiene\",\n",
        "              \"UP2_HNDWR\":\"code_upd108_handwriting\",\n",
        "              \"UP2_BED\":\"code_upd112_bed\",\n",
        "              \"UP2_TREM\":\"code_upd116_tremor\",\n",
        "              \"UP2_GETUP\":\"code_upd127_arising_from_chair\",\n",
        "              \"UP2_WALK\":\"code_upd115_walking\",\n",
        "              \"UP2_FREEZ\":\"code_upd114_freezing_of_gait\",\n",
        "              \"UP2_FALLS\":\"code_upd113_falling\",\n",
        "              \"UP2_SENS\":\"code_upd117_sensory_complaints\",\n",
        "\n",
        "\n",
        "              \"UP2\":'mds_updrs_part_ii_summary_score',\n",
        "              \"UP3\":'mds_updrs_part_iii_summary_score',\n",
        "              \"COG\":'scopa_cog_total_score',\n",
        "              \"DEP\":'depress_test_score',\n",
        "              \"IS_DEP\":\"depress_test_score/15\"}\n",
        "\n",
        "  LS1_CS, LS1_LNG = PrepKM(LS1, ls1_dict)\n",
        "\n",
        "  # LS1_LNG.loc[:,\"LTF_TD\"] = [0 if k == 0 else 1 if i > j else 0 for i, j, k in zip(LS1_LNG.daysB, LS1_LNG.CENS_DT, LS1_LNG.LTF)]\n",
        "\n",
        "  LS1_CS.to_csv(f'LS1_{LTF}_CS.csv', index=False)\n",
        "  LS1_LNG.to_csv(f'LS1_{LTF}_LNG.csv', index=False)\n",
        "  LS1_LNG.head(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaZXg8xqVYOt"
      },
      "source": [
        "%%R\n",
        "##Loads libraries required for analysis\n",
        "pack <- \"/content/gdrive/My Drive/R/packages\"\n",
        "\n",
        "library(data.table, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(dplyr, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(lubridate, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"ggplot2\", lib.loc = pack)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"survival\", lib.loc = pack)\n",
        "library(\"survminer\", lib.loc = pack)\n",
        "library(tidyr, lib.loc = pack)\n",
        "\n",
        "#Loads dataset created in python\n",
        "LS1_LTF2_CS = fread(\"LS1_LTF2_CS.csv\")\n",
        "LS1_LTF5_CS = fread(\"LS1_LTF5_CS.csv\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUsDM8Rs29ja"
      },
      "source": [
        "%%R\n",
        "# TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (sex + education_years + BL_AGE + BL_UP2 + BL_UP3 + BL_MCA + BL_GDS), data = filter(kd, Phenotype == \"PD\"))\n",
        "LS12 <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX  + BL_AGE + BL_durdx +BL_UP2 + BL_UP3 + I(BL_COG<24) + I(BL_DEP>13)), data = LS1_LTF2_CS)\n",
        "print(summary(LS12))\n",
        "\n",
        "LS15 <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX  + BL_AGE + BL_durdx + +BL_UP2 + BL_UP3 + BL_COG + BL_DEP), data = LS1_LTF5_CS)\n",
        "print(summary(LS15))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item-Level UP2 Analysis"
      ],
      "metadata": {
        "id": "znjMknN_30Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "# TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (sex + education_years + BL_AGE + BL_UP2 + BL_UP3 + BL_MCA + BL_GDS), data = filter(kd, Phenotype == \"PD\"))\n",
        "TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (BL_UP2_SPEEC + BL_UP2_SALIV +\n",
        "        BL_UP2_SWALL + BL_UP2_EAT + BL_UP2_DRESS + BL_UP2_HYGEI + BL_UP2_HNDWR + BL_UP2_BED\n",
        "        + BL_UP2_TREM + BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_FREEZ), data = LS1_LTF2_CS)\n",
        "print(summary(TI_LTF))\n",
        "\n",
        "TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (BL_UP2_SPEEC + BL_UP2_SALIV +\n",
        "        BL_UP2_SWALL + BL_UP2_EAT + BL_UP2_DRESS + BL_UP2_HYGEI + BL_UP2_HNDWR + BL_UP2_BED\n",
        "        + BL_UP2_TREM + BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_FREEZ), data = LS1_LTF5_CS)\n",
        "print(summary(TI_LTF))"
      ],
      "metadata": {
        "id": "g2IFnagP2qSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "LS1_LTF2_CS <- mutate(LS1_LTF2_CS, BL_UP2_MOB = BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_DRESS)\n",
        "LS1_LTF5_CS <- mutate(LS1_LTF5_CS, BL_UP2_MOB = BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_DRESS)\n",
        "\n",
        "TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX  + BL_AGE + BL_durdx + +BL_UP2_MOB + BL_UP3 + I(BL_COG<24) + I(BL_DEP>13)), data = LS1_LTF2_CS)\n",
        "print(summary(TI_LTF))\n",
        "\n",
        "TI_LTF <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX  + BL_AGE + BL_durdx + +BL_UP2_MOB + BL_UP3 + I(BL_COG<24) + I(BL_DEP>13)), data = LS1_LTF5_CS)\n",
        "print(summary(TI_LTF))"
      ],
      "metadata": {
        "id": "gAtMEkWJ48OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tableone as tab1\n",
        "\n",
        "pdat = LS1_LNG.drop_duplicates(keep=\"first\", subset = \"ID\")\n",
        "pdat = pdat.merge(LS1_LNG.drop_duplicates(subset = \"ID\", keep = \"last\").loc[:,[\"ID\",\"daysB\"]].rename({\"daysB\":\"FUTIME\"},axis=1), how = \"left\")\n",
        "pdat = pdat[pdat.FUTIME > 0]\n",
        "pdat.loc[:,\"FUTIME\"] = (pdat.FUTIME / 365.25).round(1)\n",
        "pdat = pdat[pdat.PHENO == \"PD\"]\n",
        "pdat.loc[:,\"IS_COG\"] = [\"DEM\" if c <= 17 else \"MCI\" if c <= 24 else \"NORM\" for c in pdat.COG]\n",
        "pdat.loc[:,\"IS_DEP\"] = [\"DEP\" if c >= 13 else \"NORM\" for c in pdat.DEP]\n",
        "\n",
        "tab1.TableOne(pdat, columns = [\"BL_AGE\",\"durdx\",\"FUTIME\", \"RACE\", \"SEX\", \"EDUC\", \"UP2\", \"UP3\", \"IS_COG\", \"IS_DEP\"],\n",
        "              nonnormal = [\"durdx\",\"FUTIME\",\"UP2\",\"UP3\"], groupby = [\"LTF\"])"
      ],
      "metadata": {
        "id": "WNwSfo7w-0aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SURE & STEADY"
      ],
      "metadata": {
        "id": "MiscgwWH_1aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUST  = pd.read_csv(f\"{datafolder}/PDBP_processed.csv\")\n",
        "SUST = SUST[SUST.study_arm.isin([\"245_PD\",\"247_PD\"])]\n",
        "\n",
        "SUST_LTF = SUST.drop_duplicates(subset = \"participant_id\", keep = \"last\").loc[:,[\"participant_id\",\"study_arm\",\"visit_month\"]]\n",
        "\n",
        "SUST_LTF.loc[:,\"lost_to_follow_up\"] = [1 if (sa == \"247_PD\") & (vm < 24)\n",
        "                          else 1 if (sa == \"245_PD\") & (vm < 24)\n",
        "                          else 0 for sa, vm in zip(SUST_LTF.study_arm, SUST_LTF.visit_month)]\n",
        "SUST_LTF.drop([\"visit_month\",\"study_arm\"], axis=1, inplace = True)\n",
        "\n",
        "SUST = SUST.merge(SUST_LTF)\n",
        "\n",
        "SUST.loc[:,\"BL_durdx\"] = SUST.age_at_baseline - SUST.age_at_diagnosis\n",
        "\n",
        "SUST.loc[:,\"education_years\"] = SUST.education_level.map({'High School/GED':0, 'Some college without degree':0,\n",
        "       'Professional or doctoral degree':1, \"Bachelor's degree\":1,\n",
        "       'Associate degree college':1, '<High School':0})\n",
        "\n",
        "gp2_cols =  [\"participant_id\", \"sex\", \"lost_to_follow_up\", \"education_level\", \"moca_total_score\",\"depress_test_score\",\n",
        "             \"code_upd2201_speech\",\"code_upd2202_saliva_and_drooling\",\"code_upd2203_chewing_and_swallowing\",\n",
        "            \"code_upd2204_eating_tasks\",\"code_upd2205_dressing\",\"code_upd2206_hygiene\",\n",
        "            \"code_upd2207_handwriting\",\"code_upd2208_doing_hobbies_and_other_activities\",\n",
        "            \"code_upd2209_turning_in_bed\",\"code_upd2210_tremor\",\"code_upd2211_get_out_of_bed_car_or_deep_chair\",\n",
        "            \"code_upd2212_walking_and_balance\",\"code_upd2213_freezing\",\"code_upd2105_apathy\",\n",
        "            \"mds_updrs_part_ii_summary_score\",\"mds_updrs_part_iii_summary_score\"]\n",
        "\n",
        "SUST_cols = {\"ID\":\"participant_id\",\n",
        "            \"LTF\":\"lost_to_follow_up\",\n",
        "            'SEX':'sex',\n",
        "            'STUDY_ARM':\"study_arm\",\n",
        "            'EDUC':'education_years',\n",
        "            \"DX_AGE\":\"age_at_diagnosis\",\n",
        "            \"DATE\":\"date_visit\",\n",
        "            \"BL_DATE\":\"date_baseline\",\n",
        "            \"BL_durdx\":\"BL_durdx\",\n",
        "            'BL_AGE':'age_at_baseline',\n",
        "\n",
        "            \"UP2\":\"mds_updrs_part_ii_summary_score\",\n",
        "            \"UP3\":\"mds_updrs_part_iii_summary_score\",\n",
        "\n",
        "            \"UP2_SPEEC\": \"code_upd2201_speech\",\n",
        "            \"UP2_SALIV\":\"code_upd2202_saliva_and_drooling\",\n",
        "            \"UP2_SWALL\":\"code_upd2203_chewing_and_swallowing\",\n",
        "            \"UP2_EAT\":\"code_upd2204_eating_tasks\",\n",
        "            \"UP2_DRESS\":\"code_upd2205_dressing\",\n",
        "            \"UP2_HYGEI\":\"code_upd2206_hygiene\",\n",
        "            \"UP2_HNDWR\":\"code_upd2207_handwriting\",\n",
        "            \"UP2_HOBBY\":\"code_upd2208_doing_hobbies_and_other_activities\",\n",
        "            \"UP2_BED\":\"code_upd2209_turning_in_bed\",\n",
        "            \"UP2_TREM\":\"code_upd2210_tremor\",\n",
        "            \"UP2_GETUP\":\"code_upd2211_get_out_of_bed_car_or_deep_chair\",\n",
        "            \"UP2_WALK\":\"code_upd2212_walking_and_balance\",\n",
        "            \"UP2_FREEZ\":\"code_upd2213_freezing\",\n",
        "            \"UP2\":'mds_updrs_part_ii_summary_score',\n",
        "            \"UP3\":'mds_updrs_part_iii_summary_score',\n",
        "            \"APAT\":\"code_upd2105_apathy\",\n",
        "            \"COG\":'moca_total_score',\n",
        "            \"DEP\":'code_upd2103_depressed_mood'\n",
        "}\n",
        "\n",
        "SUST_CS, SUST_LNG = PrepKM(SUST, SUST_cols)\n",
        "\n",
        "# PPMI_CRA = PPMI_CS.copy()\n",
        "# PPMI_CRA.loc[:,\"CRA_MCI\"] = [1 if mca < 26 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "# PPMI_CRA.loc[:,\"CRA_DEM\"] = [1 if mca < 18 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "# PPMI_CRA.loc[:,\"CRA_DEP\"] = [1 if dep == 1 else 2 if ltf == 1 else 0 for dep,ltf in zip(PPMI_CS.DEP,PPMI_CS.LTF)]\n",
        "\n",
        "SUST_CS.to_csv('SUST_KM_CS.csv', index=False)\n",
        "SUST_LNG.to_csv('SUST_KM_LNG.csv', index=False)\n",
        "SUST_CS"
      ],
      "metadata": {
        "id": "pNl-KopHl1Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Item-Level UP2 Analysis"
      ],
      "metadata": {
        "id": "7szc8KlUHIK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUST_CS[SUST_CS.STUDY_ARM == \"245_PD\"]"
      ],
      "metadata": {
        "id": "Try_RSxNtGz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "##Loads libraries required for analysis\n",
        "pack <- \"/content/gdrive/My Drive/R/packages\"\n",
        "\n",
        "library(data.table, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(dplyr, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(lubridate, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"ggplot2\", lib.loc = pack)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"survival\", lib.loc = pack)\n",
        "library(\"survminer\", lib.loc = pack)\n",
        "library(tidyr, lib.loc = pack)\n",
        "\n",
        "#Loads dataset created in python\n",
        "SUST_KM_CS = fread(\"SUST_KM_CS.csv\")\n",
        "\n",
        "print(\"******************ST COXPH*****************\")\n",
        "ST2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (SEX  + BL_AGE + +BL_UP2 + BL_UP3 + BL_COG + BL_DEP), data = filter(SUST_KM_CS, STUDY_ARM == \"245_PD\"))\n",
        "print(summary(SUST2))\n",
        "\n",
        "print(\"******************SU COXPH*****************\")\n",
        "SU2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX  + BL_AGE + BL_durdx + +BL_UP2 + BL_UP3 + BL_COG + BL_DEP), data = filter(SUST_KM_CS, STUDY_ARM == \"247_PD\"))\n",
        "print(summary(SUST2))\n",
        "\n",
        "# print(\"******************SUST COXPH UP2*****************\")\n",
        "# SUST2UP2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (BL_UP2_SPEEC + BL_UP2_SALIV +\n",
        "#         BL_UP2_SWALL + BL_UP2_EAT + BL_UP2_DRESS + BL_UP2_HYGEI + BL_UP2_HNDWR + BL_UP2_HOBBY + BL_UP2_BED\n",
        "#         + BL_UP2_TREM + BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_FREEZ), data = SUST_KM_CS)\n",
        "# print(summary(SUST2UP2))\n"
      ],
      "metadata": {
        "id": "qYrlSB9zAQw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SURE & STEADY Redux"
      ],
      "metadata": {
        "id": "zDy88Tn0fLNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SUST  = pd.read_csv(f\"{datafolder}/PPSUST_COMPLETE.csv\")\n",
        "SUST = SUST[SUST.study.isin([\"SURE\",\"STED\"])]\n",
        "\n",
        "SUST_LTF = SUST.drop_duplicates(subset = \"AMPPD_ID\", keep = \"last\").loc[:,[\"AMPPD_ID\",\"study\",\"days_in_study\"]]\n",
        "\n",
        "SUST_LTF.loc[:,\"lost_to_follow_up\"] = [1 if (sa == \"SURE\") & (vm < (365.25 * 2))\n",
        "                          else 1 if (sa == \"STED\") & (vm < (365.25 * 2))\n",
        "                          else 0 for sa, vm in zip(SUST_LTF.study, SUST_LTF.days_in_study)]\n",
        "SUST_LTF.drop([\"days_in_study\",\"study\"], axis=1, inplace = True)\n",
        "\n",
        "SUST = SUST.merge(SUST_LTF)\n",
        "\n",
        "SUST.loc[:,\"DX_AGE\"] = SUST.age_cnst_rnd - SUST.yrs_dx_base\n",
        "\n",
        "SUST_cols = {\"ID\":\"AMPPD_ID\",\n",
        "            \"LTF\":\"lost_to_follow_up\",\n",
        "            'SEX':'gender_mf',\n",
        "            'STUDY_ARM':\"study\",\n",
        "            'EDUC':'EDUCYRS',\n",
        "            \"BL_durdx\":\"yrs_dx_base\",\n",
        "            \"daysB\":\"study_dy\",\n",
        "            'BL_AGE':'age_cnst_rnd',\n",
        "            'DX_AGE':\"DX_AGE\",\n",
        "            'RACE':\"RACE\",\n",
        "            \"UP2\":\"UPDRS2\",\n",
        "            \"UP3\":\"UPDRS3\",\n",
        "            \"NHY\":\"NHY\",\n",
        "\n",
        "            \"APAT\":\"NP1APAT\",\n",
        "            \"COG\":'NP1COG',\n",
        "            \"DEP\":'NP1DPRS'\n",
        "}\n",
        "\n",
        "SUST_CS, SUST_LNG = PrepKM(SUST, SUST_cols)\n",
        "\n",
        "# PPMI_CRA = PPMI_CS.copy()\n",
        "# PPMI_CRA.loc[:,\"CRA_MCI\"] = [1 if mca < 26 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "# PPMI_CRA.loc[:,\"CRA_DEM\"] = [1 if mca < 18 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "# PPMI_CRA.loc[:,\"CRA_DEP\"] = [1 if dep == 1 else 2 if ltf == 1 else 0 for dep,ltf in zip(PPMI_CS.DEP,PPMI_CS.LTF)]\n",
        "\n",
        "SUST_CS.to_csv('SUST_KM_CS.csv', index=False)\n",
        "SUST_LNG.to_csv('SUST_KM_LNG.csv', index=False)\n",
        "SUST_CS"
      ],
      "metadata": {
        "id": "paz1F_7UiRME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "##Loads libraries required for analysis\n",
        "pack <- \"/content/gdrive/My Drive/R/packages\"\n",
        "\n",
        "library(data.table, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(dplyr, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(lubridate, lib.loc = pack, quietly = TRUE, verbose = FALSE)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"ggplot2\", lib.loc = pack)\n",
        "library(\"ggpubr\", lib.loc = pack)\n",
        "library(\"survival\", lib.loc = pack)\n",
        "library(\"survminer\", lib.loc = pack)\n",
        "library(tidyr, lib.loc = pack)\n",
        "\n",
        "#Loads dataset created in python\n",
        "SUST_KM_CS = fread(\"SUST_KM_CS.csv\")\n",
        "\n",
        "print(\"******************ST COXPH*****************\")\n",
        "ST2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX + RACE + BL_AGE + +BL_UP2 + BL_UP3 + BL_COG + BL_DEP), data = filter(SUST_KM_CS, STUDY_ARM == \"SURE\"))\n",
        "print(summary(ST2))\n",
        "\n",
        "print(\"******************SU COXPH*****************\")\n",
        "SU2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (EDUC + SEX  + BL_AGE + BL_durdx + +BL_UP2 + BL_UP3 + BL_COG + BL_DEP), data = filter(SUST_KM_CS, STUDY_ARM == \"STED\"))\n",
        "print(summary(SU2))\n",
        "\n",
        "# print(\"******************SUST COXPH UP2*****************\")\n",
        "# SUST2UP2 <- coxph(formula = Surv(daysB, LTF == 1) ~ (BL_UP2_SPEEC + BL_UP2_SALIV +\n",
        "#         BL_UP2_SWALL + BL_UP2_EAT + BL_UP2_DRESS + BL_UP2_HYGEI + BL_UP2_HNDWR + BL_UP2_HOBBY + BL_UP2_BED\n",
        "#         + BL_UP2_TREM + BL_UP2_GETUP + BL_UP2_WALK + BL_UP2_FREEZ), data = SUST_KM_CS)\n",
        "# print(summary(SUST2UP2))\n"
      ],
      "metadata": {
        "id": "ElVBDnX7m0D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RCT Meta-Analysis"
      ],
      "metadata": {
        "id": "uX_dlN_mp3lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "results_rct[[1]]"
      ],
      "metadata": {
        "id": "qYBrVCDRWvVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%R\n",
        "pack <- \"/content/gdrive/My Drive/R/packages\"\n",
        "library(metafor, lib.loc = pack)\n",
        "\n",
        "LS1 <- c(summary(LS12)$coef[,1],summary(LS12)$coef[,3])\n",
        "SUST <- c(summary(SUST2)$coef[,1],summary(SUST2)$coef[,3])\n",
        "\n",
        "results_rct <- data.frame(rbind(LS1, SUST))\n",
        "num_vars <- (length(names(results_rct)) / 2)\n",
        "for (i in 1:(num_vars-1)){\n",
        "    model2 = rma(results_rct[[i]], sei=results_rct[[i + num_vars]], slab=c(\"NET-PD\",\"SUST\"), method='REML')\n",
        "\n",
        "    print(names(results_rct)[i])\n",
        "    print(model2)\n",
        "    print(\"HR\")\n",
        "    print(exp(model2$b))\n",
        "    print(exp(model2$ci.lb))\n",
        "    print(exp(model2$ci.ub))\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "sp61LsWVzFxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# All PDBP"
      ],
      "metadata": {
        "id": "QuYqcp3UHPFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We tried with just STEADY, but the lack of events is concerning to the overall power, so we try with all PDBP\n",
        "GP2 = pd.read_csv(f\"{datafolder}/PDBP_processed.csv\")\n",
        "GP2 = GP2[GP2.Phenotype == \"PD\"] #Keep only PD cases\n",
        "# GP2 = GP2[~GP2.study_arm.isin([\"204_PD\",\"214_PD\",\"231_PD\",\"232_PD\",\"235_PD\",\"236_PD\",\"247_PD\"])] #Remove single visit studies\n",
        "# GP2\n",
        "GP2.drop_duplicates(subset = \"participant_id\",keep=\"last\").pivot_table(index=\"study_arm\",values = \"visit_month\", aggfunc = [\"count\",\"max\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "aYz3AFYlHgt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "gp2_cols =  [\"participant_id\", \"moca_total_score\",\"depress_test_score\",\n",
        "             \"code_upd2201_speech\",\"code_upd2202_saliva_and_drooling\",\"code_upd2203_chewing_and_swallowing\",\n",
        "            \"code_upd2204_eating_tasks\",\"code_upd2205_dressing\",\"code_upd2206_hygiene\",\n",
        "            \"code_upd2207_handwriting\",\"code_upd2208_doing_hobbies_and_other_activities\",\n",
        "            \"code_upd2209_turning_in_bed\",\"code_upd2210_tremor\",\"code_upd2211_get_out_of_bed_car_or_deep_chair\",\n",
        "            \"code_upd2212_walking_and_balance\",\"code_upd2213_freezing\",\"code_upd2105_apathy\",\n",
        "            \"mds_updrs_part_ii_summary_score\",\"mds_updrs_part_iii_summary_score\"]\n",
        "\n",
        "STED_GP2 = STED_GP2.loc[STED_GP2.moca_total_score.notna(),gp2_cols].drop_duplicates(subset = \"participant_id\", keep = \"first\")\n",
        "\n",
        "STED = STED.merge(STED_GP2, left_on = \"GUID\", right_on = \"participant_id\").drop(\"participant_id\",axis=1)\n",
        "\n",
        "STED_cols = {\"ID\":\"GUID\",\n",
        "            \"daysB\":\"study_dy\",\n",
        "            \"CENS_DT\":\"days_in_study_meds\",\n",
        "            \"LTF\":\"lost_to_follow_up\",\n",
        "            'SEX':'gender_mf',\n",
        "            'RACE':\"RACE\",\n",
        "            'EDUC':'EDUCYRS',\n",
        "            \"DX_AGE\":\"DX_AGE\",\n",
        "            \"BL_durdx\":\"BL_durdx\",\n",
        "            'BL_AGE':'age_cnst_rnd',\n",
        "\n",
        "\n",
        "            \"COG\":\"moca_total_score\",\n",
        "\n",
        "            \"NUP1_COG\":\"NP1COG\",\n",
        "            \"NUP1_PSYC\":\"NP1HALL\",\n",
        "            \"NUP1_DEP\":\"NP1DPRS\",\n",
        "            \"NUP1_ANX\":\"NP1ANXS\",\n",
        "            \"NUP1_APAT\":\"NP1APAT\",\n",
        "\n",
        "            \"UP1_DEP\":\"P1DEPRSN\",\n",
        "            \"UP1_APAT\":\"P1MOTIVN\",\n",
        "\n",
        "            \"UP2\":\"UPDRS2\",\n",
        "            \"UP3\":\"UPDRS3\",\n",
        "            \"OUP2\":\"OLD_UPDRS2\",\n",
        "            \"OUP3\":\"OLD_UPDRS3\",\n",
        "\n",
        "            \"UP2_SPEEC\": \"code_upd2201_speech\",\n",
        "            \"UP2_SALIV\":\"code_upd2202_saliva_and_drooling\",\n",
        "            \"UP2_SWALL\":\"code_upd2203_chewing_and_swallowing\",\n",
        "            \"UP2_EAT\":\"code_upd2204_eating_tasks\",\n",
        "            \"UP2_DRESS\":\"code_upd2205_dressing\",\n",
        "            \"UP2_HYGEI\":\"code_upd2206_hygiene\",\n",
        "            \"UP2_HNDWR\":\"code_upd2207_handwriting\",\n",
        "            \"UP2_HOBBY\":\"code_upd2208_doing_hobbies_and_other_activities\",\n",
        "            \"UP2_BED\":\"code_upd2209_turning_in_bed\",\n",
        "            \"UP2_TREM\":\"code_upd2210_tremor\",\n",
        "            \"UP2_GETUP\":\"code_upd2211_get_out_of_bed_car_or_deep_chair\",\n",
        "            \"UP2_WALK\":\"code_upd2212_walking_and_balance\",\n",
        "            \"UP2_FREEZ\":\"code_upd2213_freezing\",\n",
        "            \"UP2\":'mds_updrs_part_ii_summary_score',\n",
        "            \"UP3\":'mds_updrs_part_iii_summary_score',\n",
        "            \"APAT\":\"code_upd2105_apathy\",\n",
        "            \"COG\":'moca_total_score',\n",
        "}\n",
        "\n",
        "\n",
        "def PrepKMSTED(data, cohort_dict):\n",
        "  new_data = pd.DataFrame()\n",
        "\n",
        "  flag = 0\n",
        "  data.loc[:,\"ID\"] = data.iloc[:,0]\n",
        "  data = data.loc[:,data.columns.isin([\"ID\"] + list(cohort_dict.values()))]\n",
        "  data = data.groupby(\"ID\").fillna(method=\"bfill\")\n",
        "  for key, val in cohort_dict.items():\n",
        "    if \"IS_\" in key:\n",
        "      new_data.loc[:,key] = [np.nan if pd.isnull(i) else 1 if i >= int(val.split(\"/\")[1]) else 0 for i in data[val.split(\"/\")[0]]]\n",
        "    elif val not in data.columns:\n",
        "      print(f\"Error: {val} not found\")\n",
        "    else:\n",
        "      new_data.loc[:,key] = data[val]\n",
        "      if flag == 1:\n",
        "        new_data.loc[~new_data.ID.duplicated(keep=\"first\"),f\"BL_{key}\"] = new_data.loc[:,key]\n",
        "        new_data.loc[:,f\"BL_{key}\"] = new_data.loc[:,f\"BL_{key}\"].fillna(method = \"ffill\")\n",
        "      if key == \"BL_AGE\":\n",
        "        flag = 1\n",
        "\n",
        "  TD_data = new_data.copy()\n",
        "  TD_data.loc[:,\"LTF_TD\"] = 0 #[0 if k == 0 else 1 if i > j else 0 for i, j, k in zip(TD_data.DATE, TD_data.CENS_DT, TD_data.LTF)]\n",
        "  TD_data.loc[(~TD_data.duplicated(subset = \"ID\",keep=\"last\")) & (TD_data.LTF == 1), \"LTF_TD\"] = 1\n",
        "\n",
        "  TD_data.loc[:,\"TSTART\"] = TD_data.groupby(\"ID\").shift(1).loc[:,\"daysB\"]\n",
        "  TD_data = TD_data[TD_data.TSTART.notna()]\n",
        "  new_data = new_data.drop_duplicates(subset=\"ID\",keep=\"first\")\n",
        "  return(new_data, TD_data)\n",
        "\n",
        "\n",
        "STED_CS, STED_LNG = PrepKMSTED(STED, STED_cols)\n",
        "\n",
        "# PPMI_CRA = PPMI_CS.copy()\n",
        "# PPMI_CRA.loc[:,\"CRA_MCI\"] = [1 if mca < 26 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "# PPMI_CRA.loc[:,\"CRA_DEM\"] = [1 if mca < 18 else 2 if ltf == 1 else 0 for mca,ltf in zip(PPMI_CS.COG,PPMI_CS.LTF)]\n",
        "# PPMI_CRA.loc[:,\"CRA_DEP\"] = [1 if dep == 1 else 2 if ltf == 1 else 0 for dep,ltf in zip(PPMI_CS.DEP,PPMI_CS.LTF)]\n",
        "\n",
        "STED_CS.to_csv('STED_KM_CS.csv', index=False)\n",
        "STED_LNG.to_csv('STED_KM_LNG.csv', index=False)\n",
        "STED_CS"
      ],
      "metadata": {
        "id": "EI-00iM3HOn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tables & Figures"
      ],
      "metadata": {
        "id": "3PlpTVmIIb01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PPMI"
      ],
      "metadata": {
        "id": "jKdprUqXJI_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tableone as tab1\n",
        "\n",
        "pdat = PPMI_CS[PPMI_CS.STUDY_ARM == \"PD\"]\n",
        "\n",
        "pdat = pdat.merge(PPMI_LNG.drop_duplicates(subset = \"ID\", keep = \"last\").loc[:,[\"ID\",\"VM\"]].rename({\"VM\":\"FUTIME\"},axis=1), how = \"left\")\n",
        "# pdat = pdat[pdat.FUTIME > 0]\n",
        "pdat.loc[:,\"FUTIME\"] = (pdat.FUTIME / 12).round(1)\n",
        "# pdat = pdat[pdat.PHENO == \"PD\"]\n",
        "pdat.loc[:,\"IS_COG\"] = [\"DEM\" if c < 22 else \"MCI\" if c < 26 else \"NORM\" for c in pdat.COG]\n",
        "# pdat.loc[:,\"EDUC\"] = [\"College\" if e >= 16 else \"No College\" for e in pdat.EDUC]\n",
        "\n",
        "pdat\n",
        "tab1.TableOne(pdat.dropna(), columns = [\"BL_AGE\",\"durdx\",\"FUTIME\", \"RACE\", \"SEX\", \"EDUC\", \"UP2\", \"UP3\", \"IS_COG\", \"IS_DEP\"],\n",
        "              nonnormal = [\"durdx\",\"FUTIME\",\"UP2\",\"UP3\"], groupby = [\"LTF\"])"
      ],
      "metadata": {
        "id": "Wwv7NSYX1HY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tableone as tab1\n",
        "\n",
        "pdat = PPMI_CS[PPMI_CS.STUDY_ARM == \"PD\"]\n",
        "\n",
        "pdat = pdat.merge(PPMI_LNG.drop_duplicates(subset = \"ID\", keep = \"last\").loc[:,[\"ID\",\"VM\"]].rename({\"VM\":\"FUTIME\"},axis=1), how = \"left\")\n",
        "# pdat = pdat[pdat.FUTIME > 0]\n",
        "pdat.loc[:,\"FUTIME\"] = (pdat.FUTIME / 12).round(1)\n",
        "# pdat = pdat[pdat.PHENO == \"PD\"]\n",
        "pdat.loc[:,\"IS_COG\"] = [\"DEM\" if c < 22 else \"MCI\" if c < 26 else \"NORM\" for c in pdat.COG]\n",
        "# pdat.loc[:,\"EDUC\"] = [\"College\" if e >= 16 else \"No College\" for e in pdat.EDUC]\n",
        "\n",
        "pdat\n",
        "tab1.TableOne(pdat.dropna(), columns = [\"BL_AGE\",\"durdx\",\"FUTIME\", \"RACE\", \"SEX\", \"EDUC\", \"UP2\", \"UP3\", \"IS_COG\", \"IS_DEP\"],\n",
        "              nonnormal = [\"durdx\",\"FUTIME\",\"UP2\",\"UP3\"], groupby = [\"LTF\"])"
      ],
      "metadata": {
        "id": "VJnzl4SoIeiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NET-PD-LS1"
      ],
      "metadata": {
        "id": "EMcbhOhlOuST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdat"
      ],
      "metadata": {
        "id": "ETeBqfkyPe8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tableone as tab1\n",
        "\n",
        "pdat = LS1_CS.copy()\n",
        "\n",
        "pdat = pdat.merge(LS1_LNG.drop_duplicates(subset = \"ID\", keep = \"last\").loc[:,[\"ID\",\"VM\"]].rename({\"VM\":\"FUTIME\"},axis=1), how = \"left\")\n",
        "# pdat = pdat[pdat.FUTIME > 0]\n",
        "pdat.loc[:,\"FUTIME\"] = (pdat.FUTIME / 12).round(1)\n",
        "# pdat = pdat[pdat.PHENO == \"PD\"]\n",
        "pdat.loc[:,\"IS_COG\"] = [\"DEM\" if c < 22 else \"MCI\" if c < 26 else \"NORM\" for c in pdat.COG]\n",
        "pdat.loc[:,\"EDUC\"] = [\"College\" if e == 1 else \"No College\" for e in pdat.EDUC]\n",
        "\n",
        "pdat\n",
        "tab1.TableOne(pdat, columns = [\"BL_AGE\",\"durdx\",\"FUTIME\", \"RACE\", \"SEX\", \"EDUC\", \"UP2\", \"UP3\", \"IS_COG\", \"IS_DEP\"],\n",
        "              nonnormal = [\"durdx\",\"FUTIME\",\"UP2\",\"UP3\"], groupby = [\"LTF\"])"
      ],
      "metadata": {
        "id": "tOnutqxaOw1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b9LY0svou9S"
      },
      "source": [
        "# Archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIW4x3qxowJP"
      },
      "source": [
        "# APOE = pd.read_csv(f\"{datafolder}/PPMI.APOE.raw\",sep=\"\\t\")\n",
        "\n",
        "# APOE.loc[:,\"participant_id\"] = [int(i.split(\"-\")[-1]) for i in APOE.IID]\n",
        "\n",
        "# APOE = APOE.iloc[:,[-1,-2,-3]]\n",
        "# APOE.columns = [\"participant_id\",\"rs429358\",\"rs7412\"]\n",
        "\n",
        "# #Convert to number of risk alleles\n",
        "# APOE.loc[:,\"rs429358\"] = [abs(n-2) for n in APOE.rs429358]\n",
        "# APOE.loc[:,\"rs7412\"] = [abs(n-2) for n in APOE.rs7412]\n",
        "\n",
        "# ktdt = ktd.copy()\n",
        "\n",
        "# ktdt.loc[:,\"IS_MCI\"] = [1 if m < 26 else 0 for m in ktdt.MOCA]\n",
        "# ktdt.loc[:,\"IS_DEM\"] = [1 if m < 21 else 0 for m in ktdt.MOCA]\n",
        "\n",
        "# for col in [\"IS_MCI\",\"IS_DEM\"]:\n",
        "#   temp = APOE.merge(rmTrail(ktdt, \"IS_MCI\"))\n",
        "#   temp.to_csv(f\"k{col}.csv\")\n",
        "\n",
        "# APOE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%R\n",
        "# # install.packages(\"cmprsk\")\n",
        "# # download.file(\"http://www.stat.unipg.it/luca/misc/CumIncidence.R\", destfile = \"CumIncidence.R\")\n",
        "# source(\"CumIncidence.R\")\n",
        "\n",
        "# PPMI_CRA <- fread(\"PPMI_CRA.csv\") %>%\n",
        "#             filter(PHENO %in% c(\"PD\",\"Control\"))\n",
        "\n",
        "# fit = CumIncidence(PPMI_CRA$daysB, PPMI_CRA$CRA_DEP, PPMI_CRA$PHENO, cencode = 0, xlab=\"Days Baseline\")\n",
        "\n",
        "\n",
        "# CI.overall <- cuminc(ftime = PPMI_CRA$daysB, fstatus = PPMI_CRA$CRA_DEP)\n",
        "# plot(CI.overall, curvlab = c(\"Attrition\", \"Depression\"), xlab = \"Days\")\n",
        "\n",
        "# CI.overall <- cuminc(ftime = PPMI_CRA$daysB, fstatus = PPMI_CRA$CRA_MCI)\n",
        "# plot(CI.overall, curvlab = c(\"Attrition\", \"MCI\"), xlab = \"Days\")\n",
        "\n",
        "# CI.overall <- cuminc(ftime = PPMI_CRA$daysB, fstatus = PPMI_CRA$CRA_DEM)\n",
        "# plot(CI.overall, curvlab = c(\"Attrition\", \"Dementia\"), xlab = \"Days\")\n",
        "\n",
        "# import tableone as tab1\n",
        "\n",
        "# pdat = PPMI_LNG.drop_duplicates(keep=\"first\", subset = \"ID\")\n",
        "# pdat = pdat.merge(PPMI_LNG.drop_duplicates(subset = \"ID\", keep = \"last\").loc[:,[\"ID\",\"VM\"]].rename({\"VM\":\"FUTIME\"},axis=1), how = \"left\")\n",
        "# pdat = pdat[pdat.FUTIME > 0]\n",
        "# pdat.loc[:,\"FUTIME\"] = (pdat.FUTIME / 12).round(1)\n",
        "# pdat = pdat[pdat.PHENO == \"PD\"]\n",
        "# pdat.loc[:,\"IS_COG\"] = [\"DEM\" if c < 22 else \"MCI\" if c < 26 else \"NORM\" for c in pdat.COG]\n",
        "# pdat.loc[:,\"EDUC\"] = [\"College\" if e >= 16 else \"No College\" for e in pdat.EDUC]\n",
        "\n",
        "# tab1.TableOne(pdat, columns = [\"BL_AGE\",\"durdx\",\"FUTIME\", \"RACE\", \"SEX\", \"EDUC\", \"UP2\", \"UP3\", \"IS_COG\", \"IS_DEP\"],\n",
        "#               nonnormal = [\"durdx\",\"FUTIME\",\"UP2\",\"UP3\"], groupby = [\"LTF\"])"
      ],
      "metadata": {
        "id": "Q27h50Jbk6zE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}